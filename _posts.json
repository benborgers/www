{
  "alpine-textarea-auto-resize": "---\r\ntitle: \"How to make textarea auto-resize with Alpine.js\"\r\ndate: 2021-01-24\r\n---\r\nYou know those fancy textareas that make themselves shorter or taller depending on how much you type? That's actually really easy to do with [Alpine](https://github.com/alpinejs/alpine).\r\n\r\nResizing a textarea to be the height of its text turns out to be quite straightforward: first, set the textarea's height to almost nothing, then set the textarea's height to the height of the content that's not visible.\r\n\r\n```javascript\r\n$el.style.height = '5px'\r\n$el.style.height = $el.scrollHeight + 'px' // e.g. 152 + 'px' = '152px'\r\n```\r\n\r\n_With Alpine, `$el` is a magic variable for the element with the `x-data`._\r\n\r\nWe start by setting this as a function on our Alpine component, so we can reuse this function:\r\n\r\n```html\r\n<textarea\r\n  x-data=\"{ resize: () => { $el.style.height = '5px'; $el.style.height = $el.scrollHeight + 'px' } }\"\r\n></textarea>\r\n```\r\n\r\nNow, we simply tell Alpine to run this resizing function when the textarea first loads, and whenever someone types in the text box:\r\n\r\n```html\r\n<textarea\r\n  x-data=\"{ resize: () => { $el.style.height = '5px'; $el.style.height = $el.scrollHeight + 'px' } }\"\r\n  x-init=\"resize()\"\r\n  @input=\"resize()\"\r\n></textarea>\r\n```\r\n\r\nAnd that's it! The textarea will now resize to be the height of the text you type in it. [Here's a CodeSandbox](https://codesandbox.io/s/alpine-textarea-auto-resize-ivo9l?file=/index.html) demonstrating the solution.\r\n",
  "astro-404": "---\ntitle: How to add 404 page in Astro\ndate: 2021-06-15\n---\n\nYou can add a 404 not found page for your [Astro](https://astro.build) website just by creating a normal Astro page at `src/pages/404.astro`.\n\nMost static hosting services ([Netlify](https://netlify.com), [Vercel](https://vercel.com), etc) will pick this page up as a 404 page, and show it when there's no matching page at a given URL.\n",
  "astro-react": "---\ntitle: How to use React components in Astro\ndate: 2021-07-07\n---\n\nIn [Astro](https://astro.build), you can have some components that are in React while the rest of your site is in Astro's own templating language (or Vue, Svelte, etc).\n\nFirst create your component, with a filename such as `src/components/Counter.jsx`. In there, write a standard React component:\n\n```jsx\nimport React from 'react'\n\nexport default function Counter() {\n    return (\n        <div>Hello, world!</div>\n    )\n}\n```\n\nNext up, in your `astro.config.mjs` file add the React renderer (in addition to whatever else is already in this configuration file)\n\n```js\nexport default {\n    renderers: ['@astrojs/renderer-react']\n}\n```\n\nNow, you can import and use the React component in any `.astro` page:\n\n```js\n---\nimport Counter from '../components/Counter.jsx'\n---\n\n<Counter client:load />\n```\n\nWhere the `client:load` option is specified in the code above, there are four options:\n\n- `<Counter client:load />` renders the component on page load.\n- `<Counter client:idle />` renders the component as soon as the browser has some free time.\n- `<Counter client:visible />` renders the component only once it is scrolled into view.\n- `<Counter />` (with no option specified) renders an HTML-only version of the component, so any click handlers or state won't work.\n",
  "astro-tailwind": "---\ntitle: How to use Tailwind CSS with Astro\ndate: 2021-06-16\n---\n\nAstro has first-class support for [Tailwind](https://tailwindcss.com), so it's really easy to add Tailwind's JIT compiler to your Astro website.\n\nJust install Tailwind:\n\n```bash\nnpm install --save-dev tailwindcss\n```\n\nAnd create a file at `tailwind.config.js`:\n\n```js\n// tailwind.config.js\nmodule.exports = {\n    mode: 'jit',\n    purge: ['./public/**/*.html', './src/**/*.{astro,js,jsx,ts,tsx,vue}']\n}\n```\n\nAnd point your `astro.config.mjs` file to that Tailwind configuration file:\n\n```js\n// astro.config.mjs\nexport default {\n    devOptions: {\n        tailwindConfig: './tailwind.config.js'\n    }\n}\n```\n\nNow, create a global stylesheet in the `public/` folder, which I called `public/global.css`. In it, add the `@tailwind` directives that will output Tailwind's styles:\n\n```css\n/* public/global.css */\n@tailwind base;\n@tailwind components;\n@tailwind utilities;\n```\n\nFinally, include this CSS file in the `<head>` of HTML pages, and Tailwind CSS will work in your project!\n\n```html\n<head>\n    <link rel=\"stylesheet\" href=\"/global.css\">\n</head>\n```\n",
  "css-list-disc": "---\r\ntitle: \"How to make indented bullet points discs in CSS\"\r\ndate: 2021-01-24\r\n---\r\nBy default, indented bullet points become dots and squares instead of solid bullets.\r\n\r\nI wanted all the bullet points to stay as solid discs, because I think that it looks better:\r\n\r\n![image](https://user-images.githubusercontent.com/30215449/105643407-b1a0b180-5e5d-11eb-84d7-f47b9c16a299.png)\r\n\r\nFirst, here's the HTML for indented bullet points:\r\n\r\n```html\r\n<ul>\r\n  <li>one</li>\r\n\r\n  <ul>\r\n    <li>one a</li>\r\n  </ul>\r\n\r\n  <li>two</li>\r\n</ul>\r\n```\r\n\r\nThen, you can use this CSS to style every bullet point as a solid circle (a \"disc\"):\r\n\r\n```css\r\nli {\r\n  list-style-type: disc;\r\n}\r\n```\r\n\r\nDone! Now, ever bullet point will be the same solid disc, even if it's indented.\r\n",
  "eleventy-katex": "---\r\ntitle: \"How to use KaTeX with Eleventy\"\r\ndate: 2021-01-24\r\n---\r\n<!-- This post uses zero width spacers between the $​$ and {​{ characters so they won't be misinterpreted by Eleventy as equations or Nunjucks. -->\r\n\r\nWhen building this blog using Eleventy, I had some equations that I wanted to have rendered as LaTeX. I wrote them directly into the markdown of the posts, surrounded by two dollar signs:\r\n\r\n```markdown\r\nOne equation is $​$e = mc^2$$.\r\n```\r\n\r\nI found some ways to do this online that involved extending the markdown renderer, but I honestly really didn't understand them. Finally, I just pulled together my own solution using Eleventy's [filters](https://www.11ty.dev/docs/filters/) to modify content.\r\n\r\nFirst, go to the layout for your blog posts, and pipe the page's contents through a `latex` filter that we'll create in a moment:\r\n\r\n```html\r\n{# before: #}\r\n{​{ content | safe }}\r\n\r\n{# after: #}\r\n{​{ content | latex | safe }}\r\n```\r\n\r\nNow, we have to create that `latex` filter. First, install the KaTeX package to render math equations:\r\n\r\n```bash\r\nnpm install katex\r\n```\r\n\r\nand import it in your `.eleventy.js` file:\r\n\r\n```javascript\r\nconst katex = require('katex')\r\n```\r\n\r\nNow, we can write the `latex` filter in your `.eleventy.js` file:\r\n\r\n```javascript\r\neleventyConfig.addFilter('latex', content => {\r\n  return content.replace(/\\$\\$(.+?)\\$\\$/g, (_, equation) => {\r\n    const cleanEquation = equation\r\n      .replace(/&lt;/g, '<')\r\n      .replace(/&gt;/g, '>')\r\n\r\n    return katex.renderToString(cleanEquation, { throwOnError: false })\r\n  })\r\n})\r\n```\r\n\r\nWhat this does is it registers a new Eleventy filter called `latex`, which will affect the `content` of our page.\r\n\r\nWe take the content of the page and use a regex to replace every occurrence of `$$something$​$`. We're using `\\$` to escape the dollar sign, because `$` has a special meaning in regex but we want the actual dollar sign character (not its special meaning).\r\n\r\nWhen rendering markdown to HTML, Eleventy likes to change characters like `>` to `&gt;`, etc. This stops those characters from rendering as actual HTML. However, here we want to turn these characters _back_ into what they were before, since we might've used the `>` or `<` characters in our equations.\r\n\r\nWe use KaTeX's `renderToString` method to render this equation so it looks like an actual equation, and replace the `$​$something$$` with that rendered KaTeX HTML.\r\n\r\nFinally, add this CSS file to your layout's `<head>`. It loads the necessary fonts and CSS to display the equations.\r\n\r\n```html\r\n<link rel=\"stylesheet\" href=\"https://unpkg.com/katex@latest/dist/katex.min.css\" />\r\n```\r\n\r\nAnd that's it! Now, any LaTeX written in your markdown in the format `$​$equation here$$` will be beautifully rendered on the page.\r\n",
  "eleventy-tailwind": "---\r\ntitle: \"How to use Tailwind with Eleventy\"\r\ndate: 2021-01-24\r\n---\r\nIf you have an Eleventy site and want to add Tailwind CSS to it, first install these npm packages: `tailwindcss`, `postcss`, `postcss-cli`, `autoprefixer`, and `cssnano`.\r\n\r\nPostCSS is a tool for outputting your Tailwind CSS file, and `postcss-cli` will allow us to run it from the terminal. `autoprefixer` and `cssnano` are plugins for PostCSS that make the CSS work in more browsers and minify the CSS.\r\n\r\nNext, run this command to set up your Tailwind and PostCSS configuration files (which will be named `tailwind.config.js` and `postcss.config.js`):\r\n\r\n```bash\r\nnpx tailwindcss init -p\r\n```\r\n\r\nIn your `tailwind.config.js` file, set the `purge` property. This will allow Tailwind to remove all unused CSS when building your Eleventy site, which makes it **much** faster.\r\n\r\n```\r\npurge: [ '_site/**/*.html' ],\r\n```\r\n\r\n_This is by far the easiest way I've figured out to do it. It looks through the outputted HTML files of your site in `_site`, so keep in mind that you have to generate your CSS **after** generating the Eleventy site._\r\n\r\nModify your `postcss.config.js` file so that it looks like this, so that you're using all the plugins we installed:\r\n\r\n```js\r\nmodule.exports = {\r\n  plugins: {\r\n    tailwindcss: {},\r\n    autoprefixer: {},\r\n    cssnano: {}\r\n  }\r\n}\r\n```\r\n\r\nLast step: create your actual CSS file that will get turned into Tailwind CSS. I like to put it at `./style.css`, and fill it with this:\r\n\r\n```css\r\n@tailwind base;\r\n@tailwind components;\r\n@tailwind utilities;\r\n```\r\n\r\nNow you can use this command to create a \"development\" build of your CSS:\r\n\r\n```bash\r\npostcss style.css > _site/style.css\r\n```\r\n\r\nAnd this command and create a \"production\" build of your CSS (with all the unused classes taken out):\r\n\r\n```bash\r\nNODE_ENV=production postcss style.css > _site/style.css\r\n```\r\n\r\nIn practice, I like to include these in the `package.json` scripts for my project, so I can build the CSS and develop/build the site at the same time. That part of my `package.json` looks like this:\r\n\r\n```json\r\n\"scripts\": {\r\n  \"dev\": \"rm -rf _site && mkdir _site && postcss style.css > _site/style.css && eleventy --serve --quiet\",\r\n  \"build\": \"rm -rf _site && eleventy && NODE_ENV=production postcss style.css > _site/style.css\"\r\n},\r\n```\r\n\r\n_Notice that, when building the site in production, I'm first building the site using the `eleventy` command and then building the CSS. This allows Tailwind to look at the  `_site` directory where my Eleventy site is outputted and figure out which classes I didn't use._\r\n\r\nNow you can run the `npm run dev` command to develop your Eleventy site, and the `npm run build` command to build the site and CSS.\r\n\r\nTo use the new `style.css` file outputted, just include it in your Eleventy templates:\r\n\r\n```html\r\n<link rel=\"stylesheet\" href=\"/style.css\" />\r\n```\r\n",
  "embroider-svg": "---\ntitle: How to digitize an SVG for embroidery\ndate: 2021-03-29\n---\n\n*This method is free, but requires some technical know-how.*\n\nFirst, you're going to need to install [Processing](https://processing.org/).\n\nThen, follow the given instructions to install the [PEmbroider](https://github.com/CreativeInquiry/PEmbroider) library for for Processing.\n\nOpen up Processing, and copy and paste in this script. I can't write Processing code, but I modified [this example](https://github.com/CreativeInquiry/PEmbroider/blob/master/examples/PEmbroider_svg_image/PEmbroider_svg_image.pde).\n\n```java\nimport processing.embroider.*;\nPEmbroiderGraphics E;\n\nPShape mySvgImage;\n\nvoid setup() {\n  size(500, 500);\n  noLoop();\n\n  E = new PEmbroiderGraphics(this, width, height);\n  String outputFilePath = sketchPath(\"myfile.pes\");\n  E.setPath(outputFilePath);\n\n  PShape mySvgImage = loadShape(\"myfile.svg\");\n  E.fill(0,0,0);\n  E.stroke(0,0,0);\n  E.strokeWeight(1);\n  E.hatchSpacing(2);\n  E.setStitch(5, 15, 0);\n\n  E.hatchMode(E.CROSS);\n  E.shape(mySvgImage, 0, 0, 500, 500);\n\n  //E.optimize();\n  E.visualize();\n  //E.endDraw();\n}\n\nvoid draw() {\n  ;\n}\n\n```\n\nIn the Processing toolbar, go to **Sketch > Show Sketch Folder**. In here, create a folder called `data/` and then drop your SVG file into this folder. Rename `myfile.svg` in the script to point to its filename, and change `myfile.pes` to change what the outputted file will be called.\n\nA few things you can tweak about this script:\n\n- `hatchSpacing` controls how close together the lines are. I've found that `2` is usually pretty good.\n- In the line that says `E.shape`, the first two numbers control which coordinate the shape starts and ends at. The next two control the dimensions of the shape: right now it's a 500 x 500 square, but we'll change that in a moment.\n\nRun the script in Processing, and look at the output. It'll be square-ish, and if your original SVG wasn't square, that means it'll be distorted. Change the third and fourth numbers in `E.shape` to give it the right shape, continuing to re-run the script until it looks right.\n\nOnce you're happy, uncomment the lines that say `E.optimize()` and `E.endDraw()`. `optimize` optimizes the output, but this can take several minutes. `endDraw` actually saves your file, which will be outputted to the \"sketch folder\" from earlier.\n\nRun the script again. When the preview window with the shape pops up, you'll know that the outputted file is in the sketch folder. You can now load that `.pes` file onto a USB stick and have your machine embroider it.\n",
  "emoji-favicon": "---\r\ntitle: \"How to use an emoji as a favicon\"\r\ndate: 2021-01-24\r\n---\r\nYou can't directly use an emoji as a favicon, a favicon needs to be an image.\r\n\r\nHowever, you can get an image of the emoji using [EMOJICDN](https://emojicdn.elk.sh):\r\n\r\n```html\r\n<link rel=\"icon\" href=\"https://emojicdn.elk.sh/🍉\" />\r\n```\r\n\r\nJust replace the `🍉` emoji with any emoji you'd like.\r\n",
  "emojicdn-how": "---\r\ntitle: \"How to programmatically get an image for any emoji\"\r\ndate: 2021-01-24\r\n---\r\nI wanted to be able to get a PNG image of any emoji, so I built a quick API for it.\r\n\r\nIt's called [EMOJICDN](https://emojicdn.elk.sh), and all you have to do is go to `emojicdn.elk.sh/<emoji>` to get an image of that emoji. For example (try it!):\r\n\r\n[emojicdn.elk.sh/🐢](https://emojicdn.elk.sh/🐢)\r\n\r\nBy default, the API returns the Apple artwork for the emoji. However, you can pass in a `?style=` parameter to get another platform's artwork. A full list of supported styles is [documented here](https://github.com/benborgers/emojicdn#emoji-style).\r\n\r\n[emojicdn.elk.sh/🐢?style=messenger](https://emojicdn.elk.sh/🐢?style=messenger)\r\n",
  "emojicdn": "---\r\ntitle: \"An API to get the image for any emoji\"\r\ndate: 2021-01-23\r\n---\r\nI built an API called [EMOJICDN](https://emojicdn.elk.sh) that lets you pass in any emoji and get a PNG for Apple's artwork of that emoji.\r\n\r\nFor example: [emojicdn.elk.sh/🤩](http://emojicdn.elk.sh/🤩)\r\n\r\nIt uses the Apple versions of the emojis because I think those are the most recognizable and good-looking.\r\n\r\n## Uses\r\n\r\nYou can also use that link as the source of an img html element.\r\n\r\nI also often use it as a quick and easy favicon:\r\n\r\n```html\r\n<link rel=\"icon\" href=\"https://emojicdn.elk.sh/🤩\" />\r\n```\r\n\r\nThe source code for the API is [open source](https://github.com/benborgers/emojicdn), and there's more details at [emojicdn.elk.sh](http://emojicdn.elk.sh/).\r\n",
  "emotion-global": "---\r\ntitle: \"How to add global CSS to Gatsby with Emotion\"\r\ndate: 2021-01-24\r\n---\r\nBy default, CSS you add with [Emotion](https://emotion.sh) is scoped to the component where it was added.\r\n\r\nTo add global CSS, use the `Global` component provided by Emotion:\r\n\r\n```jsx\r\nimport React from \"react\"\r\nimport { css, Global } from \"@emotion/core\"\r\n\r\nexport default () => {\r\n  return (\r\n    <Global\r\n      styles={css`\r\n        * {\r\n          font-family: Helvetica, sans-serif;\r\n        }\r\n      `}\r\n    />\r\n  )\r\n}\r\n```\r\n\r\nThe CSS written in the `styles` prop of `Global` will be injected globally into your Gatsby site.\r\n",
  "error-spread-array-tslib": "---\ntitle: \"Fix: export '__spreadArray' was not found in 'tslib'\"\ndate: 2021-04-09\n---\n\nI ran into this error when using `framer-motion`, but it looks like it affects several packages.\n\nI was able to fix it just by running this command:\n\n```bash\nnpm up\n```\n",
  "expo-app-name": "---\r\ntitle: \"How to fix Expo \\\"the app name you entered is already being used\\\"\"\r\ndate: 2021-01-24\r\n---\r\nSo you run `expo upload:ios` and get this error:\r\n\r\n> The app name you entered is already being used. If you have trademark rights to this name and would like it released for your use, submit a claim.\r\n\r\n![](https://user-images.githubusercontent.com/30215449/105642222-70f16a00-5e56-11eb-84df-54ee9405df32.png)\r\n\r\nWhat's going on here is that the Apple App Store doesn't allow multiple apps with the same name.\r\n\r\nYou need to upload the app again to App Store Connect, but using a different name (this is why you see a lot of apps called \"Shine: Calm Anxiety & Stress\", instead of \"Shine\").\r\n\r\nYou don't need to change the app's name in your `app.json` file though. This means that your app's name on people's home screens will stay the same as you defined in `app.json`.\r\n\r\nTo change only the name of the app in the App Store, and not on the home screen, run this command instead:\r\n\r\n```bash\r\nexpo upload:ios --app-name \"My App - Unique Name\"\r\n```\r\n",
  "expo-ip": "---\r\ntitle: \"How to get the device's IP address with Expo\"\r\ndate: 2021-01-24\r\n---\r\nFirst, install the `expo-network` package:\r\n\r\n```bash\r\nexpo install expo-network\r\n```\r\n\r\nThen, import the package in the file you'd like to use it:\r\n\r\n```javascript\r\nimport * as Network from \"expo-network\"\r\n```\r\n\r\nNow, you can use the `Network` object to get the IP address:\r\n\r\n```javascript\r\nconst ip = await Network.getIpAddressAsync()\r\n```\r\n",
  "expo-mailto": "---\r\ntitle: \"How to open up the email composer with Expo\"\r\ndate: 2021-01-24\r\n---\r\n_Note: this won't work properly when testing on iOS Simulators since you can't sign into a mail account on the simulator._\r\n\r\nInstall the `expo-mail-composer` package to your Expo project:\r\n\r\n```bash\r\nexpo install expo-mail-composer\r\n```\r\n\r\nNow, you can import and use the module. For example:\r\n\r\n```javascript\r\nimport * as MailComposer from \"expo-mail-composer\"\r\n\r\n// Opens prefilled email\r\nMailComposer.composeAsync({\r\n  recipients: [], // array of email addresses\r\n  subject: \"\",\r\n  body: \"\"\r\n})\r\n```\r\n",
  "expo-screen-height": "---\r\ntitle: \"How to get screen height in Expo\"\r\ndate: 2021-01-24\r\n---\r\nThe screen height can be retrieved using the `Dimensions` package:\r\n\r\n```javascript\r\nimport Dimensions from \"react-native\"\r\n\r\nDimensions.get(\"window\").height\r\n```\r\n",
  "expo-screen-width": "---\r\ntitle: \"How to get screen width in Expo\"\r\ndate: 2021-01-24\r\n---\r\nThe screen width can be retrieved using the `Dimensions` package:\r\n\r\n```javascript\r\nimport Dimensions from \"react-native\"\r\n\r\nDimensions.get(\"window\").width\r\n```\r\n",
  "expo-version": "---\r\ntitle: \"How to get the current app version in Expo\"\r\ndate: 2021-01-24\r\n---\r\nYou often want to show the version number of your app to the user.\r\n\r\nIn an Expo (React Native) app, you can do this using the `expo-constants` package, provided by Expo.\r\n\r\nFirst, install the package:\r\n\r\n```bash\r\nexpo install expo-constants\r\n```\r\n\r\nThen, add the package to the file where you want to get the version number:\r\n\r\n```javascript\r\nimport Constants from \"expo-constants\"\r\n```\r\n\r\nNow, you can access `Constants.manifest`, which is the current \"manifest\" (`app.json` file) of your app. The version number is available like this:\r\n\r\n```javascript\r\nconst version = Constants.manifest.version\r\n```\r\n",
  "express-access-cookies": "---\r\ntitle: \"How to access cookies with Express\"\r\ndate: 2021-01-24\r\n---\r\nThe best way to access cookies with an Express server is using the `cookie-parser` middleware package.\r\n\r\nInstall it:\r\n\r\n```bash\r\nnpm install cookie-parser\r\n```\r\n\r\nAnd then add it to your server:\r\n\r\n```jsx\r\nconst express = require(\"express\")\r\nconst app = express()\r\n\r\nconst cookieParser = require(\"cookie-parser\")\r\napp.use(cookieParser())\r\n\r\n// the rest of your Express server...\r\n```\r\n\r\nYou can then access the cookies of any request:\r\n\r\n```jsx\r\napp.get(\"/\", (req, res) => {\r\n  const cookies = req.cookies\r\n  const token = req.cookies.token\r\n\r\n  // ...etc\r\n})\r\n```\r\n",
  "express-password-protect": "---\r\ntitle: \"How to password protect a route with Express\"\r\ndate: 2021-01-24\r\n---\r\nYou can password protect a Glitch site if you're writing Node.js (which means you've got a `package.json` file).\r\n\r\nWe're going to be using `express`, the default Node.js server framework that new Glitch projects use. We're also going to be using a technique called **Basic authentication**, which is built into every browser.\r\n\r\nThis is what it'll look like:\r\n\r\n![image](https://user-images.githubusercontent.com/30215449/105643112-05aa9680-5e5c-11eb-96d3-c489211a0e63.png)\r\n\r\nLet's say we want to password-protect this secret admin route:\r\n\r\n```javascript\r\nconst express = require('express')\r\nconst app = express()\r\n\r\napp.get('/admin', (req, res) => {\r\n  res.send('Top secret stuff here')\r\n})\r\n```\r\n\r\nHere's a code snippet of how to do it, and then I'll explain how it works:\r\n\r\n```javascript\r\napp.get('/admin', (req, res) => {\r\n  const reject = () => {\r\n    res.setHeader('www-authenticate', 'Basic')\r\n    res.sendStatus(401)\r\n  }\r\n\r\n  const authorization = req.headers.authorization\r\n\r\n  if(!authorization) {\r\n    return reject()\r\n  }\r\n\r\n  const [username, password] = Buffer.from(authorization.replace('Basic ', ''), 'base64').toString().split(':')\r\n\r\n  if(! (username === 'ben' && password === 'my-favorite-password')) {\r\n    return reject()\r\n  }\r\n\r\n  res.send('Top secret stuff here')\r\n})\r\n```\r\n\r\nFirst, we create a function called `reject()`, which is used to prevent a person from viewing the page. This function sets a header that instructs the browser to ask for a username and password, and otherwise sends a `401 Unauthorized` error code.\r\n\r\nIf the visitor types a username and password into the prompt, it'll be sent via a header called `authorization` in the format below. However, everything after `Basic ` will be encoded in base64 format:\r\n\r\n```\r\nBasic myusername:mypassword\r\n```\r\n\r\nSo first, if there's no `authorization` header, we immediately `reject()` the request as unauthorized. This can happen if the user clicks \"cancel\" on the login form.\r\n\r\nOtherwise, we first take the `authorization` header and remove the portion that says `Basic ` (including the space after). We then decode it from base64 format to text using `Buffer.from()`, then turn it into a string and split the `:` separating the username and password. Since this split creates an array, we can assign the parts of the array to the variables `username` and `password`.\r\n\r\nLastly, we check whether the `username` and `password` are what we expect them to be. If they aren't, we `reject()` the request.\r\n\r\nIf the request has made it all the way to the end, the user has provided the correct username and password. We can finish the request by sending back any data or file, knowing that they have the correct credentials to view it.\r\n",
  "express-powered-by": "---\r\ntitle: \"How to disable the \\\"x-powered-by\\\" header in Express\"\r\ndate: 2021-01-24\r\n---\r\n[Express](https://expressjs.com) generates a header to your responses that says `x-powered-by: Express`.\r\n\r\nIf you want to clean up your headers, just add:\r\n\r\n```jsx\r\napp.disable(\"x-powered-by\")\r\n```\r\n\r\nat the top of your javascript file.\r\n",
  "express-set-cookies": "---\r\ntitle: \"How to set and delete cookies with Express\"\r\ndate: 2021-01-24\r\n---\r\n## Setting cookies\r\n\r\n```jsx\r\nres.cookie(\"token\", MY_TOKEN, { maxAge: MILLISECONDS_FROM_NOW_TO_EXPIRE })\r\n```\r\n\r\nThere's more options (other than `maxAge`) described in the [Express documentation](https://expressjs.com/en/api.html#res.cookie).\r\n\r\n## Deleting cookies\r\n\r\n```jsx\r\nres.clearCookie(\"token\")\r\n```\r\n",
  "fathom-gatsby": "---\r\ntitle: \"How to add Fathom Analytics to Gatsby\"\r\ndate: 2021-01-23\r\n---\r\n[Fathom](https://usefathom.com/ref/TUIPJE) offers simple and privacy-focused analytics that you can use for your Gatsby site.\r\n\r\nUsing the new hosted Fathom script, you can just drop this snippet into the `<head>` of every Gatsby page you want to track. (You can use a package like [react-helmet](https://npm.im/react-helmet) with [gatsby-plugin-react-helmet](https://www.gatsbyjs.org/packages/gatsby-plugin-react-helmet/) to insert things into the HTML head).\r\n\r\n```html\r\n<script src=\"https://cdn.usefathom.com/script.js\" spa=\"auto\" site=\"ABCDEF\" defer></script>\r\n```\r\n\r\nMake sure to change the `site` code to your site ID. You can also use your [Fathom custom domain](https://usefathom.com/support/custom-domains) instead of the default `src`.\r\n\r\nWith Fathom's new tracking script, the `spa=\"auto\"` attribute will make it automatically work with Gatsby, so you no longer need to use a Gatsby plugin to help Fathom detect when the page changes.\r\n",
  "feature-branches-clients": "---\r\ntitle: \"How to use Git feature branches in Netlify for clients\"\r\ndate: 2021-01-24\r\n---\r\nI recently wrote a guide on [how to use feature branches in Git](/posts/feature-branches).\r\n\r\nI also wanted to add that I use this technique a lot for client websites, if the client has requested a hefty change to their website that I'm not sure they'll actually like.\r\n\r\nI create a branch for the change, code the change, and then push it to the repository on GitHub. From there, I can use [Netlify](https://netlify.com) to [deploy all branches of my repository](https://docs.netlify.com/site-deploys/overview/#branch-deploy-controls), and send the client a link with that specific branch deployed.\r\n\r\nThey can try the change live, and if they like it, I merge the feature branch into `master` (as described in my [other post](/posts/feature-branches)).\r\n\r\nIf they don't like it, I can just delete the branch instead of spending hours undoing my work.\r\n",
  "feature-branches": "---\r\ntitle: \"How to use feature branches in Git and GitHub\"\r\ndate: 2021-01-24\r\n---\r\nGit feature branches are a workflow that involves creating separate branches for each feature you want to build. When a feature is finished, it gets merged into the central `master` branch.\r\n\r\nThis enables multiple features to be built in parallel on different branches, without overlapping over each other.\r\n\r\nIt also allows you to maintain a stable `master` branch in case the feature gets thrown away or starts to ruin everything.\r\n\r\n## Creating the branch\r\n\r\nFirst make sure you're on the `master` branch (if not, run `git checkout master` to switch to it).\r\n\r\nThen, create a new branch from `master` and switch onto it (replace `<feature_branch>`with the name you choose for your feature branch).\r\n\r\n```bash\r\ngit checkout -b <feature_branch>\r\n```\r\n\r\nFrom here, you can do all your work as you would usually. Commit and push new changes for the feature to this new branch.\r\n\r\n## Merging the branch to master\r\n\r\nOnce you're done with the your work on the branch and want to merge it into `master`, run these four commands:\r\n\r\n```bash\r\ngit checkout master\r\ngit pull origin master\r\ngit merge <feature_branch_name>\r\ngit push origin master\r\n```\r\n\r\n1. Switch to the `master` branch\r\n2. Make sure you have the most up-to-date changes from `master`\r\n3. Merge your feature branch (replace `<feature_branch>` with your branch's name)\r\n4. Push the changes to the remote host (for example, GitHub)\r\n\r\n## Cleaning up\r\n\r\nAfterwards, you'll probably want to delete the feature branch. These two commands first delete the branch on the remote host, then delete the branch locally.\r\n\r\n```bash\r\ngit push -d origin <feature_branch>\r\ngit branch -d <feature_branch>\r\n```\r\n",
  "gatsby-active-link": "---\r\ntitle: \"How to style the currently active link in Gatsby\"\r\ndate: 2021-01-23\r\n---\r\nIn Gatsby, you using the `<Link>` component to create links to other pages on your Gatsby site.\r\n\r\nIt's fairly common to highlight the currently active page in a site navigation bar, to show a visitor where in the navigation they are. Gatsby's `<Link>` component provides a built-in way to style a link that points to the page the visitor is currently looking at.\r\n\r\n## Add CSS to the currently active class\r\n\r\n```jsx\r\n<Link\r\n  to=\"/about/\"\r\n  activeStyle={{\r\n    color: \"blue\",\r\n    fontWeight: 700\r\n  }}\r\n>\r\n  About\r\n</Link>\r\n```\r\n\r\n## Add a CSS class to the currently active link\r\n\r\n```jsx\r\n<Link\r\n  to=\"/about/\"\r\n  activeClassName=\"active\"\r\n>\r\n  About\r\n</Link>\r\n```\r\n",
  "gatsby-favicon": "---\r\ntitle: \"How to add a favicon with Gatsby\"\r\ndate: 2021-01-24\r\n---\r\nTo add a favicon to your Gatsby site, you need to be able to add code to the `<head>` of your page.\r\n\r\nFor that, you can use [`react-helmet`](https://github.com/nfl/react-helmet) (developed by the National Football League, by the way).\r\n\r\nTo use `react-helmet` in Gatsby, install the package and a Gatsby plugin to make it work:\r\n\r\n```bash\r\nnpm install react-helmet gatsby-plugin-react-helmet\r\n```\r\n\r\nThen, add `gatsby-plugin-react-helmet` to your `gatsby-config.js` file:\r\n\r\n```javascript\r\n// gatsby-config.js\r\n\r\nmodule.exports = {\r\n  plugins: [\r\n    \"gatsby-plugin-react-helmet\",\r\n    // other plugins, if you have them\r\n  ]\r\n}\r\n```\r\n\r\nNow, on your Gatsby page (for example `src/pages/index.js`), use `react-helmet` to add the meta tag for a shortcut icon.\r\n\r\n```jsx\r\nimport React from \"react\"\r\nimport { Helmet } from \"react-helmet\"\r\n\r\nexport default () => {\r\n  return (\r\n    <React.Fragment>\r\n      <Helmet>\r\n        <meta name=\"icon\" href=\"/link/to/favicon.png\" />\r\n      <Helmet>\r\n\r\n      <div>\r\n        Hello, world!\r\n      </div>\r\n    </React.Fragment>\r\n  )\r\n}\r\n```\r\n",
  "gatsby-google-fonts": "---\r\ntitle: \"How to use Google Fonts with Gatsby\"\r\ndate: 2021-01-27\r\n---\r\nFirst, install `react-helmet-async` and `@rhysforyou/gatsby-plugin-react-helmet-async`. These allow you to add things to the `<head>` of your pages.\r\n\r\n```bash\r\nnpm install react-helmet-async @rhysforyou/gatsby-plugin-react-helmet-async\r\n```\r\n\r\nThen, add the `@rhysforyou/gatsby-plugin-react-helmet-async` plugin to your [`gatsby-config.js`](https://www.gatsbyjs.org/docs/gatsby-config/) file:\r\n\r\n```jsx\r\n// gatsby-config.js\r\n\r\nmodule.exports = {\r\n  plugins: [\r\n    \"@rhysforyou/gatsby-plugin-react-helmet-async\"\r\n  ]\r\n}\r\n```\r\n\r\nYou may need to restart the Gatsby development server (run `gatsby develop` again) in order to see the changes to your `gatsby-config.js` file.\r\n\r\nNow, select a couple [Google Fonts](https://fonts.google.com), click **Embed**, and copy the **<link>** option.\r\n\r\n![](https://user-images.githubusercontent.com/30215449/105642337-2de3c680-5e57-11eb-8dd4-67e1f0e52a57.png)\r\n\r\n\r\nLastly, you're ready to add this font embed code to your Gatsby page's `<head>` using `react-helmet-async`:\r\n\r\n```jsx\r\n// src/pages/index.js\r\n\r\nimport React from \"react\"\r\nimport { Helmet } from \"react-helmet-async\" // make sure to import Helmet\r\n\r\nexport default () => {\r\n  return (\r\n    <>\r\n      <Helmet>\r\n        {/* copy and paste the embed from Google Fonts: */}\r\n        <link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap\" rel=\"stylesheet\" />\r\n      </Helmet>\r\n\r\n      <div>\r\n        the rest of the page...\r\n      </div>\r\n    </>\r\n  )\r\n}\r\n```\r\n\r\nNotice the added `/` at the end of the `<link ... />` above. You'll need to make this change to the code you copy and paste from Google Fonts.\r\n\r\nThis is because React requires tags that don't have a closing tag (such as `link`) to be self-closing, with an added `/` (for example `<img />`, not `<img>`).\r\n",
  "gatsby-last-built": "---\r\ntitle: \"How to get the last time a Gatsby site was built\"\r\ndate: 2021-01-23\r\n---\r\nIf your Gatsby site pulls in data at build time, it can be helpful to show visitors when the site was last built.\r\n\r\nThis component relies on a GraphQL query to fetch the build time, and then formats it using a lightweight package called [tiny-relative-date](https://npm.im/tiny-relative-date).\r\n\r\nHere is an abbreviated component using it (without styling):\r\n\r\n```jsx\r\nimport React from \"react\"\r\nimport { useStaticQuery, graphql } from \"gatsby\"\r\nimport relativeDate from \"tiny-relative-date\"\r\n\r\nexport default () => {\r\n  const query = useStaticQuery(graphql`\r\n    query {\r\n      site {\r\n        buildTime\r\n      }\r\n    }\r\n  `)\r\n\r\n  const buildTime = new Date(query.site.buildTime)\r\n  const buildTimeRelative = relativeDate(buildTime)\r\n\r\n  return (\r\n    <p>This site was last built {buildTimeRelative}.</p>\r\n  )\r\n}\r\n```\r\n",
  "gatsby-meta": "---\r\ntitle: \"What meta tags you need for a Gatsby site\"\r\ndate: 2021-01-23\r\n---\r\nIn almost every Gatsby site I make, I create a `<Head />` component with all the meta tags I'll need. I reuse that component on every page, passing in different titles and descriptions.\r\n\r\nThere's definitely more meta tags you could use, but I've whittled it down to this component:\r\n\r\n```jsx\r\nimport React from \"react\"\r\nimport { Helmet } from \"react-helmet\"\r\n\r\nexport default ({ title, description, shareImage }) => {\r\n  return (\r\n    <Helmet>\r\n      <title>{title}</title>\r\n      <meta name=\"description\" content={description} />\r\n\r\n      <meta property=\"og:type\" content=\"website\" />\r\n      <meta property=\"og:site_name\" content=\"My Site\" />\r\n      <meta property=\"og:title\" content={title} />\r\n      <meta property=\"og:description\" content={description} />\r\n      <meta property=\"og:image\" content={shareImage} />\r\n\r\n      <meta property=\"twitter:card\" content=\"summary_large_image\" />\r\n\r\n      <link rel=\"icon\" href=\"/link/to/favicon.png\" />\r\n    </Helmet>\r\n  )\r\n}\r\n```\r\n\r\n## A couple notes\r\n\r\n- There's some repeats (`title` and `og:title`, `description` and `og:description`), but since this is a reusable component it isn't really more work to include both.\r\n- The `og:image` is quite important to me, because a nice share image makes the link stand out when it's shared on Twitter or elsewhere.\r\n- The `twitter:card` tag tells Twitter to make the share image as large as possible in a tweet.\r\n- You can also add equivalent `twitter:title` etc tags, but Twitter falls back on `og:` tags, so there's no need to include both.\r\n",
  "gatsby-react-helmet-async": "---\r\ntitle: \"How to use react-helmet-async with Gatsby\"\r\ndate: 2021-01-24\r\n---\r\nWhen you replace `react-helmet` with `react-helmet-async`, you can use the Gatsby plugin [@rhysforyou/gatsby-plugin-react-helmet-async](https://www.gatsbyjs.org/packages/@rhysforyou/gatsby-plugin-react-helmet-async/) to make it work with Gatsby.\r\n\r\nJust install the plugin:\r\n\r\n```bash\r\nnpm install @rhysforyou/gatsby-plugin-react-helmet-async\r\n```\r\n\r\nAnd include the plugin in `gatsby-config.js`:\r\n\r\n```jsx\r\nmodule.exports = {\r\n  plugins: [\r\n    \"@rhysforyou/gatsby-plugin-react-helmet-async\"\r\n  ]\r\n}\r\n```\r\n\r\nNow, you can use `react-helmet-async` in your Gatsby site:\r\n\r\n```jsx\r\nimport React from \"react\"\r\nimport { Helmet } from \"react-helmet-async\"\r\n\r\nexport default () => {\r\n  return (\r\n    <Helmet>\r\n      <title>Candlemaker Corner</title>\r\n    </Helmet>\r\n  )\r\n}\r\n```\r\n",
  "gatsby-sitemap": "---\r\ntitle: \"How to create a sitemap for a Gatsby site\"\r\ndate: 2021-01-24\r\n---\r\nInstall the Gatsby plugin:\r\n\r\n```bash\r\nnpm install gatsby-plugin-sitemap\r\n```\r\n\r\nThen, add the root URL of your site (before the part that starts with `/`) to your `gatsby-config.js`, and activate the plugin:\r\n\r\n```javascript\r\n// gatsby-config.js\r\n\r\nmodule.exports = {\r\n  siteMetadata: {\r\n    siteUrl: \"https://benborgers.com\"\r\n  },\r\n  plugins: [\r\n    \"gatsby-plugin-sitemap\"\r\n  ]\r\n}\r\n```\r\n\r\nDone! Your sitemap will be created at `/sitemap.xml` in production builds of your Gatsby website, and will also be properly linked in the `<head>` of each page.\r\n",
  "github-syntax-highlighting": "---\r\ntitle: \"How to get syntax highlighting in HTML generated by GitHub\"\r\ndate: 2021-01-24\r\n---\r\nGitHub has its own markdown renderer. Maybe you're using a package like Caleb Porzio's [GitDown](https://github.com/calebporzio/gitdown), which internally uses the GitHub API to parse markdown. Or maybe you're using the GitHub API to get the contents of an issue.\r\n\r\nIn any case, you're letting GitHub render the markdown.\r\n\r\nGitHub's markdown renderer adds classes inside code blocks, which are used for syntax highlighting (making some parts of the code a different color than others). However, you need the right CSS file to make those different classes different colors.\r\n\r\nPer the [github-syntax-theme-generator](https://github.com/primer/github-syntax-theme-generator) repository, you've got two options. Pick one of these two CSS files, copy and paste the line into your HTML's `<head>`, and it'll syntax highlight the markdown outputted by GitHub's API.\r\n\r\n```html\r\n<!-- for light background -->\r\n<link rel=\"stylesheet\" href=\"https://unpkg.com/github-syntax-light@latest/lib/github-light.css\" />\r\n\r\n<!-- for dark background -->\r\n<link rel=\"stylesheet\" href=\"https://unpkg.com/github-syntax-dark@latest/lib/github-dark.css\" />\r\n```\r\n",
  "glitch-awake": "---\r\ntitle: \"How to keep your Glitch project from sleeping\"\r\ndate: 2021-01-30\r\n---\r\n_Note: you might not be able to use this method (or any method) to keep your Glitch projects awake anymore, since [Glitch has blocked ping services](https://blog.glitch.com/post/ping-services)._\r\n\r\n---\r\n\r\n[Glitch](https://glitch.com) projects sleep after 5 minutes if they're not used.\r\n\r\nThen, the next time you access the project, you'll see a loading screen for a few seconds:\r\n\r\n![](https://user-images.githubusercontent.com/30215449/105642152-f88aa900-5e55-11eb-9f08-aa0bc621b5c7.png)\r\n\r\nIf you have a Glitch project that you don't want going to sleep, use [cron-job.org](https://cron-job.org).\r\n\r\nA cron job is a task that happens at a certain interval. In this case, we're going to make a request to your Glitch project every 5 minutes so that it doesn't fall asleep.\r\n\r\n1. Create a [cron-job.org](https://cron-job.org) account for free, and then [create a new cron job](https://cron-job.org/en/members/jobs/add/).\r\n2. Fill out the title, URL (your Glitch project link), and schedule it for every 5 minutes.\r\n3. Create the cron job.\r\n\r\n![](https://user-images.githubusercontent.com/30215449/105642162-04766b00-5e56-11eb-829e-93be7ff12b5c.png)\r\n\r\nDone! cron-job.org will make a request to your Glitch project's URL every 5 minutes, keeping the project awake for free.\r\n",
  "glitch-cors": "---\r\ntitle: \"How to fix CORS errors on Glitch\"\r\ndate: 2021-01-24\r\n---\r\nCORS is a security measure that stops a web page on one domain from fetching resources from another domain.\r\n\r\nHowever, sometimes you do want to do this: for example, your website (on one domain) is pulling data from the backend on [Glitch](https://glitch.com), which has another domain (like `your-project.glitch.me`).\r\n\r\nFixing this issue falls into two categories: you control the server you're fetching from (for example, you're fetching a resource from your own Glitch project), or you don't control the server you're fetching from (it's someone else's website). Here's how to fix both:\r\n\r\n## Scenario 1: You control the server\r\n\r\nIf you're trying to fetch a resource from your own server (like your own Glitch project), but you're getting blocked by CORS errors, you need to tell your server to allow fetching from other domains.\r\n\r\nYou can do this really easily if you're using the popular [Express](https://expressjs.com) Node.js framework, which is the most popularly used on Glitch.\r\n\r\nFirst, install the npm package `cors` either by adding it on Glitch in your `package.json` file, or by running this command in the console:\r\n\r\n```bash\r\nnpm install cors\r\n```\r\n\r\nThen, import it and use it in your Express app:\r\n\r\n```jsx\r\nconst express = require(\"express\")\r\nconst app = express()\r\n\r\nconst cors = require(\"cors\") // importing the `cors` package\r\napp.use(cors()) // tells Express to use `cors`, and solves the issue\r\n\r\napp.listen(3000) // tells Express which port to listen on\r\n```\r\n\r\nThis should open your server up to requests from other domains, fixing the CORS issue.\r\n\r\n## Scenario 2: You don't control the server\r\n\r\nIf you're fetching resources from some other server that you don't control, you can't install and run code on that server like in Scenario 1.\r\n\r\nInstead, you can use a *proxy server*, which is a server that sits in between your website and the resource you're trying to access.\r\n\r\nMy recommendation is the free service [cors-anywhere](https://cors-anywhere.herokuapp.com/), which will fetch the resource for you and then return it with the proper CORS configuration to allow you to access it.\r\n\r\nEssentially, it's a middleman that grabs what you want, and then turns around and gives it to you.\r\n\r\nFollow the instructions on the [cors-anywhere](https://cors-anywhere.herokuapp.com/) site to learn how to use it to make requests to any website without running into CORS errors.\r\n",
  "glitch-cron-job": "---\r\ntitle: \"How to set up a cron job for your Glitch project\"\r\ndate: 2021-01-24\r\n---\r\nA cron job allows you to run some code on a schedule (every day at 9am, every hour at 10 minutes past the hour, etc).\r\n\r\nWith Glitch, you can do that by writing the code in your Glitch project, and then triggering the code to run externally.\r\n\r\nFirst, set up an [Express](https://expressjs.com) route that contains the code you want to run:\r\n\r\n```javascript\r\napp.get(\"/cron\", (req, res) => {\r\n  // the code you want to run\r\n\r\n  res.sendStatus(200) // sends an \"OK\" response\r\n})\r\n```\r\n\r\nThis means that when you go to `https://project-name.glitch.me/cron` in your browser, the code will execute.\r\n\r\nNow, instead of opening that page manually, we'll use an external service to make an HTTP request to the `/cron` endpoint and run that code.\r\n\r\nGo to [cron-job.org](http://cron-job.org) and sign up (it's free). Then, [view your cron jobs](https://cron-job.org/en/members/jobs/) and click the \"Create\" button.\r\n\r\nGive the job a name that describes it, and put the `https://project-name.glitch.me/cron` URL as the one where a request should be made.\r\n\r\nConfigure the schedule options so it runs at the frequency you'd like, and click \"Create cronjob\" at the bottom of the page.\r\n\r\nDone! Now, cron-job.org will make an HTTP request to that URL at the frequency you told them to, triggering the code in the `/cron` route to run automatically.\r\n",
  "glitch-disk-space": "---\ntitle: \"How to avoid running out of disk space with a database on Glitch\"\ndate: 2021-01-24\n---\nSince originally writing this blog post, I've since found that the best way to solve a problem like this is to add the database file(s) to your `.gitignore` file.\n\nThis tells git not to keep a record of changes to your database, which avoids clogging up your disk space with local git history.\n",
  "glitch-password-protect": "---\r\ntitle: \"How to password protect your Glitch site\"\r\ndate: 2021-01-24\r\n---\r\nYou can password protect a Glitch site if you're writing Node.js (which means you've got a `package.json` file).\r\n\r\nWe're going to be using `express`, the default Node.js server framework that new Glitch projects use. We're also going to be using a technique called **Basic authentication**, which is built into every browser.\r\n\r\nThis is what it'll look like:\r\n\r\n![](https://user-images.githubusercontent.com/30215449/105643146-2f63bd80-5e5c-11eb-809a-c84cfccf02f0.png)\r\n\r\nLet's say we want to password-protect this secret admin route:\r\n\r\n```javascript\r\nconst express = require('express')\r\nconst app = express()\r\n\r\napp.get('/admin', (req, res) => {\r\n  res.send('Top secret stuff here')\r\n})\r\n```\r\n\r\nHere's a code snippet of how to do it, and then I'll explain how it works:\r\n\r\n```javascript\r\napp.get('/admin', (req, res) => {\r\n  const reject = () => {\r\n    res.setHeader('www-authenticate', 'Basic')\r\n    res.sendStatus(401)\r\n  }\r\n\r\n  const authorization = req.headers.authorization\r\n\r\n  if(!authorization) {\r\n    return reject()\r\n  }\r\n\r\n  const [username, password] = Buffer.from(authorization.replace('Basic ', ''), 'base64').toString().split(':')\r\n\r\n  if(! (username === 'ben' && password === 'my-favorite-password')) {\r\n    return reject()\r\n  }\r\n\r\n  res.send('Top secret stuff here')\r\n})\r\n```\r\n\r\nFirst, we create a function called `reject()`, which is used to prevent a person from viewing the page. This function sets a header that instructs the browser to ask for a username and password, and otherwise sends a `401 Unauthorized` error code.\r\n\r\nIf the visitor types a username and password into the prompt, it'll be sent via a header called `authorization` in the format below. However, everything after `Basic ` will be encoded in base64 format:\r\n\r\n```\r\nBasic myusername:mypassword\r\n```\r\n\r\nSo first, if there's no `authorization` header, we immediately `reject()` the request as unauthorized. This can happen if the user clicks \"cancel\" on the login form.\r\n\r\nOtherwise, we first take the `authorization` header and remove the portion that says `Basic ` (including the space after). We then decode it from base64 format to text using `Buffer.from()`, then turn it into a string and split the `:` separating the username and password. Since this split creates an array, we can assign the parts of the array to the variables `username` and `password`.\r\n\r\nLastly, we check whether the `username` and `password` are what we expect them to be. If they aren't, we `reject()` the request.\r\n\r\nIf the request has made it all the way to the end, the user has provided the correct username and password. We can finish the request by sending back any data or file, knowing that they have the correct credentials to view it.\r\n",
  "google-sheets-json": "---\r\ntitle: \"How to get a Google Sheet as JSON\"\r\ndate: 2021-01-23\r\n---\r\nGoogle Sheets can be a great place to store content for a website, since it's structured and easy to update (especially for non-coders).\r\n\r\nThere's a very useful but obscure way of getting an API for reading a Google Sheet, that doesn't require authentication or complicated permissions. Plus, it updates immediately when the spreadsheet is edited, without delay!\r\n\r\n1. To start, open the Google Sheet and go to **File → Publish to the web**. Publish the entire document, so that it can be accessed without logging in.\r\n2. Copy and paste the *spreadsheet key*, which is the long random string in the URL of the spreadsheet. Make sure to copy the entire random part of the URL between two slashes.\r\n3. Then, use the URL endpoint below to get the spreadsheet's contents, replacing `spreadsheet_key` with your spreadsheet key from the last step:\r\n\r\n```\r\nhttps://spreadsheets.google.com/feeds/list/spreadsheet_key/1/public/values?alt=json\r\n```\r\n\r\nThat's it! If you go to that URL in your browser (substituting your spreadsheet key in the URL), you'll see JSON that contains the contents of your spreadsheet.\r\n\r\n## Optional step: formatting the data\r\n\r\nI always reformat the data from this API before I use it, since I think the way it's returned by default isn't very usable.\r\n\r\nHere's some example code I use to format the data, using the `fetch` method in JavaScript ([docs here](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)):\r\n\r\n```jsx\r\nfetch(\"https://spreadsheets.google.com/feeds/list/1wQ1TGqnCTmaqqDak1rTRxPMSGSGLMilwrecf7TuqDGc/1/public/values?alt=json\")\r\n  .then(res => res.json())\r\n  .then(json => {\r\n    const data = [] /* this array will eventually be populated with the contents of the spreadsheet's rows */\r\n\r\n    const rows = json.feed.entry\r\n\r\n    for(const row of rows) {\r\n      const formattedRow = {}\r\n\r\n      for(const key in row) {\r\n        if(key.startsWith(\"gsx$\")) {\r\n\r\n          /* The actual row names from your spreadsheet\r\n           * are formatted like \"gsx$title\".\r\n           * Therefore, we need to find keys in this object\r\n           * that start with \"gsx$\", and then strip that\r\n           * out to get the actual row name\r\n           */\r\n\r\n          formattedRow[key.replace(\"gsx$\", \"\")] = row[key].$t\r\n\r\n        }\r\n      }\r\n\r\n      data.push(formattedRow)\r\n    }\r\n\r\n    console.log(data) /* do anything you want with the reformatted data here */\r\n  })\r\n```\r\n\r\nThe above code will produce a `data` array that looks like this:\r\n\r\n```js\r\n[\r\n  {\r\n    image: \"1\",\r\n    resource: \"\",\r\n    section: \"math\",\r\n    test: \"1874FPRE\",\r\n    firstanswer: \"a\",\r\n    totalanswers: \"5\",\r\n    correctanswer: \"c\"\r\n  },\r\n  {\r\n    image: \"2\",\r\n    resource: \"\",\r\n    section: \"math\",\r\n    test: \"1874FPRE\",\r\n    firstanswer: \"f\",\r\n    totalanswers: \"5\",\r\n    correctanswer: \"k\"\r\n  },\r\n  ...\r\n]\r\n```\r\n\r\nOf course, it's up to you how you parse and use the spreadsheet data for your app.\r\n\r\n## Bonus: reading the other sheets in your spreadsheet\r\n\r\nIn Google Sheets, you can add multiple \"sheets\", which are like multiple pages. If you'd like to read the contents of the second sheet of your spreadsheet, replace the `1` in the URL with `2` (or whatever number sheet you'd like to read):\r\n\r\n```\r\nhttps://spreadsheets.google.com/feeds/list/spreadsheet_key/2/public/values?alt=json\r\n```\r\n",
  "grid-center": "---\r\ntitle: \"Center vertically and horizontally on the page with CSS Grid\"\r\ndate: 2021-01-24\r\n---\r\nHere's how you can center this div on a page:\r\n\r\n```html\r\n<body>\r\n  <div>center me</div>\r\n</body>\r\n```\r\n\r\n```css\r\nbody {\r\n  min-height: 100vh;\r\n  display: grid;\r\n  place-items: center center;\r\n}\r\n```\r\n\r\nThese 3 lines of CSS:\r\n- Make the body as tall as the device's screen, so centering something actually looks centered\r\n- Indicate that you want to use CSS grid\r\n- Place the grid's one \"item\" (the div) in the center vertically and the center horizontally\r\n",
  "instagram-bio": "---\r\ntitle: \"How to update your Instagram bio with Node.js\"\r\ndate: 2021-01-24\r\n---\r\nInstagram's API is for businesses only, but the unofficial npm package [`instagram-private-api`](https://npm.im/instagram-private-api) will allow you to access Instagram's API.\r\n\r\nFirst, install the package in your Node.js project:\r\n\r\n```bash\r\nnpm install instagram-private-api\r\n```\r\n\r\nThen, you can use this code to update your bio:\r\n\r\n```javascript\r\nconst { IgApiClient } = require(\"instagram-private-api\")\r\nconst ig = new IgApiClient()\r\n\r\nconst USERNAME = \"bborgers\"\r\nconst PASSWORD = \"hackme\"\r\n\r\nig.state.generateDevice(USERNAME)\r\n\r\nconst main = async () => {\r\n  await ig.simulate.preLoginFlow()\r\n  await ig.account.login(USERNAME, PASSWORD)\r\n\r\n  // log out of Instagram when done\r\n  process.nextTick(async () => await ig.simulate.postLoginFlow())\r\n\r\n  // fill in whatever you want your new Instagram bio to be\r\n  await ig.account.setBiography(`It is currently ${new Date().toLocaleString()}`)\r\n}\r\n\r\nmain()\r\n// code is written in main() so that I can use async/await\r\n```\r\n\r\nThat's how easy it is to update your Instagram bio using Node.js and some programming!\r\n\r\nCheck out [`instagram-private-api`'s GitHub repo](https://github.com/dilame/instagram-private-api) — there's a ton of cool stuff to play with.\r\n",
  "ios-15-safari-theme-color": "---\ntitle: How to change iOS 15 Safari status bar color\ndate: 2021-06-14\n---\n\nOn the iOS 15 update of Safari, there's a colored top bar in the background at the top of the screen.\n\nYou can change what color this is by setting a `theme-color` meta property in the `<head>` of the HTML page:\n\n```html\n<meta name=\"theme-color\" content=\"#EF4444\" />\n```\n\nThis will change the color of the section of the interface behind the status bar, above the website itself.\n",
  "js-array-remove-duplicates": "---\r\ntitle: \"How to remove duplicates in an array in JavaScript\"\r\ndate: 2021-01-24\r\n---\r\nLet's say you have this array:\r\n\r\n```javascript\r\nconst myArray = [\"red\", \"blue\", \"green\", \"blue\", \"blue\", \"orange\", \"green\"]\r\n```\r\n\r\nBut you only want each item to appear once.\r\n\r\nHere's how you turn that array into an array where each item only appears once.\r\n\r\n```javascript\r\nconst uniqueArray = [...new Set(myArray)]\r\n```\r\n",
  "js-audio": "---\r\ntitle: \"How to play an audio file with JavaScript\"\r\ndate: 2021-01-30\r\n---\r\nPlaying a sound with pure javascript is surprisingly easy. First, you need a URL to the audio file you want to play. We'll use this one:\r\n\r\n```\r\nhttps://www.w3schools.com/html/horse.mp3\r\n```\r\n\r\nNow, all it takes is two lines of code to play that sound file:\r\n\r\n```javascript\r\nconst sound = new Audio('https://www.w3schools.com/html/horse.mp3')\r\nsound.play()\r\n```\r\n",
  "js-back-and-refresh": "---\r\ntitle: \"How to go back one page and refresh with JavaScript\"\r\ndate: 2021-01-30\r\n---\r\nLet's say you want to have a link that sends the user back one page, but also refreshes the page so that last page's content isn't stale.\r\n\r\nHere's a way you can do it:\r\n\r\n```javascript\r\n// On button press, or something else:\r\ndocument.referrer ? window.location = document.referrer : history.back()\r\n```\r\n\r\nThis looks to see if we have a `referrer`, which is the last page that the user came from before this page. If there is, we navigate to that page.\r\n\r\nIf there isn't, we fall back to using `history.back()` as an alternative, which sends the user back _without_ refreshing.\r\n",
  "js-copy-text": "---\r\ntitle: \"How to copy text with JavaScript\"\r\ndate: 2021-01-24\r\n---\r\nYou can only copy text for the user if it's in an `input` or `textarea`.\r\n\r\n```html\r\n<input class=\"copy-to-clipboard\" />\r\n```\r\n\r\nIf you don't want to have a visible `input` element on the page, you can add this CSS to the input so that it still exists (in the top left corner) but isn't visible or clickable:\r\n\r\n```css\r\ninput.copy-to-clipboard {\r\n  opacity: 0;\r\n  pointer-events: none; /* to ignore clicks */\r\n  position: absolute;\r\n  top: 0;\r\n  left: 0;\r\n}\r\n```\r\n\r\nNow that you've got the `input` element, you can use JavaScript to fill the value of the input and copy that text to the clipboard:\r\n\r\n```jsx\r\nconst copyText = (text) => {\r\n  const input = document.querySelector(\"input.copy-to-clipboard\")\r\n  input.value = text\r\n  input.select()\r\n  input.setSelectionRange(0, 9999) // selects characters 0 through 9,999 in the input\r\n  document.execCommand(\"copy\")\r\n  document.activeElement.blur() // deselects the input\r\n}\r\n```\r\n",
  "js-double-spaces": "---\r\ntitle: \"How to remove double spaces in a string in JavaScript\"\r\ndate: 2021-01-30\r\n---\r\nHere's how you can use regex in JavaScript to remove double spaces:\r\n\r\n```javascript\r\nconst string = 'Here is my sentence.  There are  double spaces.'\r\n\r\nconst newString = string.replace(/ {2,}/g, ' ')\r\n```\r\n\r\nThis regex replaces any two or more spaces in a row with a single space.\r\n",
  "js-hash-passwords": "---\r\ntitle: \"How to hash passwords in Node.js\"\r\ndate: 2021-01-24\r\n---\r\nHashing passwords before saving them to the database is extremely important for security.\r\n\r\nA *hash* is an algorithm that scrambles up a password in a way that cannot be reversed, but happens the same way each time.\r\n\r\nWhen a user signs up, you should take their password, hash it, and then store the resulting \"hash\". This means that you never store their actual password in plain text. Later, if you need to check whether the password they provided is correct, you can hash what they send you and compare the outcome with what you saved. If the two hashes are the same, the user provided the same password both times.\r\n\r\nThe most popular library for hashing passwords in Node.js is [`bcrypt`](https://www.npmjs.com/package/bcrypt). First install the package:\r\n\r\n```bash\r\nnpm install bcrypt\r\n```\r\n\r\nand then include it in Node.js so you can use it:\r\n\r\n```javascript\r\nconst bcrypt = require(\"bcrypt\")\r\n```\r\n\r\nWhen you first receive the password and want to store it in the database:\r\n\r\n```javascript\r\nconst SALT_ROUNDS = 10\r\n// \"Salt rounds\" controls how long it takes to hash a password.\r\n// Increasing this by 1 doubles the time it takes to hash a password.\r\n// Higher number means more security, but it'll be slower.\r\n\r\nconst hashedPassword = await bcrypt.hash(realPassword, SALT_ROUNDS)\r\n// Store hashedPassword in your database\r\n// Never store realPassword in case your database gets exposed\r\n```\r\n\r\nWhen checking whether the password you received is the correct one, using the `bcrypt.compare` method:\r\n\r\n```javascript\r\n/*\r\n * providedPassword is what the user claims is their password\r\n * for example through a login form\r\n *\r\n * Retrieve hashedPassword from database.\r\n */\r\nconst passwordIsCorrect = await bcrypt.compare(providedPassword, hashedPassword)\r\n// Returns true if they match, false if they don't\r\n```\r\n",
  "js-hash": "---\r\ntitle: \"How to read and change URL hash with JavaScript\"\r\ndate: 2021-01-24\r\n---\r\nYou can read the current URL hash (the part of the URL after `#`) like this:\r\n\r\n```javascript\r\nconst hash = location.hash\r\nconsole.log(hash)\r\n```\r\n\r\nAnd change it like this:\r\n\r\n```javascript\r\nlocation.hash = \"foo\"\r\n```\r\n\r\nYou can detect whenever the hash changes like this:\r\n\r\n```javascript\r\nwindow.addEventListener(\"hashchange\", event => {\r\n  console.log(\"hash changed\", event)\r\n})\r\n```\r\n",
  "js-object-changes": "---\r\ntitle: \"How to detect when an object changes in JavaScript\"\r\ndate: 2021-01-24\r\n---\r\nYou can use a JavaScript feature called a [Proxy](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy) to define how properties of an object are read and set.\r\n\r\nThe `Proxy` takes a target (the object that the `Proxy` is wrapping), and a handler (which defines how the `Proxy` should act).\r\n\r\nHere's an example:\r\n\r\n```javascript\r\nconst sourceObject = {}\r\n\r\nconst handler = {\r\n  get: (target, key) => {\r\n    if(typeof target[key] === \"object\" && target[key] !== null) {\r\n      return new Proxy(target[key], handler)\r\n    }\r\n\r\n    return target[key]\r\n  },\r\n  set: (target, prop, value) => {\r\n      target[prop] = value\r\n      console.log(\"A change was made!\")\r\n    return true\r\n  }\r\n}\r\n\r\nconst object = new Proxy(sourceObject, handler)\r\n```\r\n\r\nIn the `get` method of the `Proxy`'s handler, we check whether what we're returning is of type `object` (an array, object, etc). If it is, we wrap it in a new `Proxy` using the same handler as itself.\r\n\r\nThis is to ensure that all changes go through this `Proxy`, and the `console.log` statement runs for every change.\r\n\r\nIf we didn't wrap objects returned from the `get` method in another `Proxy`, this kind of \"deeper\" change would not result in a `console.log`:\r\n\r\n```javascript\r\n// continuing example from above\r\n\r\nobject.list = [] // \"A change was made!\"\r\nobject.list.push(\"foo\") // no console.log statement\r\n```\r\n",
  "js-relative-date": "---\r\ntitle: \"How to format relative date with Node.js\"\r\ndate: 2021-01-24\r\n---\r\nA relative date is something like \"23 minutes ago\", \"1 day ago\", or \"3 months ago\".\r\n\r\nMy favorite Node.js package for formatting a normal `Date` object into a nice string is [tiny-relative-date](https://www.npmjs.com/package/tiny-relative-date).\r\n\r\nFirst, install the package:\r\n\r\n```bash\r\nnpm install tiny-relative-date\r\n```\r\n\r\nThen, you can use it like this:\r\n\r\n```javascript\r\nconst relativeDate = require(\"tiny-relative-date\") // import the package\r\n\r\nconst date = new Date() // any javascript date object\r\n\r\nconsole.log(relativeDate(date)) // this returns the relative date\r\n```\r\n\r\nDone! Now you've got relative dates in Node.js.\r\n",
  "js-remove-hash": "---\r\ntitle: \"How to remove hash from URL with JavaScript\"\r\ndate: 2021-01-24\r\n---\r\nYou usually clear the URL hash like this:\r\n\r\n```javascript\r\nlocation.hash = \"\"\r\n```\r\n\r\nHowever, that leaves a `#` at the end of the URL. You can remove the `#` by adding a line of code:\r\n\r\n```javascript\r\nlocation.hash = \"\"\r\nhistory.replaceState(\"\", \"\", location.pathname)\r\n```\r\n\r\nThe second line overwrites the URL with the current URL, minus the `#`.\r\n",
  "js-snow": "---\r\ntitle: \"How to add falling snow to a website with JavaScript\"\r\ndate: 2021-02-01\r\n---\r\nI wanted to add a snowing animation to my website, but I didn't want to code it myself. Instead, I found a nice package called [let-it-go](https://github.com/EastSun5566/let-it-go) to do it for me.\r\n\r\nJust install the package:\r\n\r\n```shell\r\nnpm i let-it-go\r\n```\r\n\r\nAnd then start the confetti:\r\n\r\n```javascript\r\nimport { LetItGo } from 'let-it-go'\r\n\r\nnew LetItGo({\r\n    color: '#94a3b8'\r\n    /* color is optional (the snow is white by default),\r\n       but since my website was white I needed gray snow for contrast */\r\n})\r\n```\r\n\r\nThere's more options for stopping and styling the snow in the [let-it-go docs](https://github.com/EastSun5566/let-it-go).\r\n",
  "js-textarea-auto-resize": "---\r\ntitle: \"How to make auto-resizing textarea with JavaScript\"\r\ndate: 2021-01-24\r\n---\r\nHere's how to make one of those fancy textareas that gets shorter and taller depending on how much text is in it, using pure javascript.\r\n\r\nFirst, all you need is a plain HTML text box:\r\n\r\n```html\r\n<textarea></textarea>\r\n```\r\n\r\nNext, in the javascript, we're going to write a function that makes the textarea the correct height based on how much text is in it. It first makes the text box very short, and then makes it as tall as the content that is _not visible_.\r\n\r\n```javascript\r\nconst textarea = document.querySelector('textarea')\r\n\r\nconst resize = () => {\r\n  textarea.style.height = '5px'\r\n  textarea.style.height = textarea.scrollHeight + 'px' // e.g. 152 + 'px' = '152px'\r\n}\r\n```\r\n\r\nNow, all we have to do is run this function once the page loads, and run it again every time someone types into the text box:\r\n\r\n```javascript\r\nresize() // run once immediately\r\n\r\ntextarea.addEventListener('input', resize)\r\n```\r\n\r\nAnd that's it! The text box will now change height to accommodate how much text you type into it. [Here's a CodeSandbox](https://codesandbox.io/s/js-textarea-auto-resize-yz0k8?file=/index.html) demonstrating the solution.\r\n",
  "json-ld": "---\r\ntitle: \"How to use JSON-LD to improve SEO on a developer blog\"\r\ndate: 2021-01-23\r\n---\r\nI want the title, description, and publish date to be really clear when Google looks at my blog posts. After some searching, I decided to add metadata to my articles in the JSON-LD format.\r\n\r\nJSON-LD is a specific set of data that you often add to the `<head>` of your blog post, which hidden metadata about your page.\r\n\r\nI did a bunch of fiddling with Google's [structured data testing tool](https://search.google.com/structured-data/testing-tool/), and finally landed on adding this to the blog post template of my Gatsby blog:\r\n\r\n```html\r\n<script type=\"application/ld+json\">\r\n  {\r\n    \"@context\": \"https://schema.org\",\r\n    \"@type\": \"BlogPosting\",\r\n    \"headline\": \"How to use JSON-LD to improve SEO on a developer blog\",\r\n    \"image\": \"https://benborgers.com/assets/json-ld.png\",\r\n    \"publisher\": {\r\n      \"@type\": \"Organization\",\r\n      \"name\": \"Ben Borgers\",\r\n      \"url\": \"https://benborgers.com\",\r\n      \"logo\": {\r\n        \"@type\": \"ImageObject\",\r\n        \"url\": \"https://benborgers.com/assets/index.png\",\r\n        \"width\": \"1200\",\r\n        \"height\": \"630\"\r\n      }\r\n    },\r\n    \"url\": \"https://benborgers.com/posts/json-ld/\",\r\n    \"datePublished\": \"2020-01-06T00:00:00.000Z\",\r\n    \"dateCreated\": \"2020-01-06T00:00:00.000Z\",\r\n    \"dateModified\": \"2020-01-06T00:00:00.000Z\",\r\n    \"description\": \"Adding data to your developer blog in the JSON-LD format, like the title, description, share image, author, and date published, can make it easier for Google to parse and index your articles.\",\r\n    \"author\": {\r\n      \"@type\": \"Person\",\r\n      \"name\": \"Ben Borgers\",\r\n      \"url\": \"https://benborgers.com\"\r\n    },\r\n    \"mainEntityOfPage\": {\r\n      \"@type\": \"WebPage\",\r\n      \"@id\": \"https://benborgers.com/posts/\"\r\n    }\r\n  }\r\n</script>\r\n```\r\n\r\nMost of the lines are fairly self-explanatory:\r\n\r\n- Defining that the page is a blog post (type \"BlogPosting\")\r\n- Defining the title, description, and share image for the page\r\n- Recording dates when the blog post was published, created, and modified\r\n\r\nGoogle's testing tool also complained that I didn't have an author and a publisher, so I added both.\r\n\r\nThe `mainEntityOfPage` property defines what this page is an \"entity\", or part, of. In my case, these blog posts are a part of my larger blog.\r\n\r\nAdding this script tag to the blog post template of my Gatsby blog has allowed Google to more easily parse and index my articles.\r\n",
  "kill-localhost": "---\r\ntitle: \"How to kill a localhost process on macOS\"\r\ndate: 2021-01-23\r\n---\r\nSometimes you've got a development server running on a localhost port in the background that you can't seem to stop.\r\n\r\nFor example, if the port is `localhost:8000`, run:\r\n\r\n```bash\r\nsudo lsof -i :8000\r\n```\r\n\r\nYou should see the processes running on that port. Take note of the `PID` for these processes.\r\n\r\nThen, run:\r\n\r\n```bash\r\nkill -9 <PID>\r\n```\r\n",
  "laravel-artisan-commands-not-working": "---\r\ntitle: \"Artisan commands not working in fresh Laravel installation\"\r\ndate: 2021-01-24\r\n---\r\nI just created a new Laravel app and installed Jetstream, and when I went to run `php artisan serve` it hung and didn't do anything.\r\n\r\nThen, I tried to run `php artisan migrate`, and it also stalled for a while before giving me an error that the database connection had timed out.\r\n\r\nThis was weird, because it was a completely fresh installation of Laravel and Jetstream with no changes made.\r\n\r\nI eventually realized that the issue lay in the `.env` file. The new Laravel installation has a `.env` file with these values:\r\n\r\n```env\r\nDB_CONNECTION=mysql\r\n# DB_HOST=127.0.0.1\r\nDB_HOST=mysql\r\nDB_PORT=3306\r\nDB_DATABASE=laravel\r\nDB_USERNAME=root\r\nDB_PASSWORD=\r\n```\r\n\r\nThe `DB_HOST` variable is no longer set to localhost, like it used to be, but my local MySQL database for development is running at `localhost:3306` (which is the same as `127.0.0.1:3306`).\r\n\r\nTo fix it, all I had to do was uncomment the first `DB_HOST` line by removing the `#`, and then remove the line that says `DB_HOST=mysql`.\r\n\r\nThen, `php artisan serve` and `php artisan migrate` worked perfectly again.\r\n",
  "laravel-double-spaces": "---\r\ntitle: \"How to remove double spaces in a string in Laravel\"\r\ndate: 2021-01-30\r\n---\r\nHere's how you can use Laravel's `Str` helper to remove double spaces from a string in PHP, using regex:\r\n\r\n```php\r\nuse Illuminate\\Support\\Str;\r\n\r\n$string = 'Here is my sentence.  There are  double spaces.';\r\n\r\n$newString = Str::of($string)->replaceMatches('/ {2,}/', ' ');\r\n```\r\n\r\nThis takes any part of the string that matches ` {2,}` (a space character occurring two or more times in a row) and replaces it with a single space.\r\n",
  "laravel-log-404": "---\r\ntitle: \"How to log or record 404 errors in Laravel\"\r\ndate: 2021-01-26\r\n---\r\nWhen I moved my personal website to Laravel, I wanted to make sure that I hadn't forgotten to move some important routes. Therefore, I wanted to keep a log of all the \"404 not found\" errors that happened on my website.\r\n\r\nI was originally going to listen for the error to be thrown within the app, but then found out that Laravel ignores 404 errors for you.\r\n\r\nInstead, I settled on a hacky (but simple and effective!) solution:\r\n\r\nYou can customize Laravel's 404 error page by creating a view at `resources/views/errors/404.blade.php`. I built a simple \"not found\" page there, and then wrote the PHP code I wanted to run in the view within a `@php` blade directive in that view:\r\n\r\n```blade\r\n{{-- resources/views/errors/404.blade.php --}}\r\n\r\n@php\r\n    $array = Cache::get('404') ?? [];\r\n    $array[] = '/' . request()->path();\r\n    Cache::forever('404', $array);\r\n@endphp\r\n```\r\n\r\nThis code adds the current URL to an array that's stored in the cache, so I can see which URLs people are going to but that don't exist.\r\n",
  "laravel-mix-notifications": "---\r\ntitle: \"How to disable Laravel Mix notifications\"\r\ndate: 2021-01-24\r\n---\r\nLaravel Mix sends a desktop notification every time it re-compiles your assets, which can be pretty annoying.\r\n\r\nTo turn that off, add this line to your `webpack.mix.js` file:\r\n\r\n```javascript\r\nmix.disableNotifications()\r\n```\r\n\r\nDone! No more notifications from Laravel Mix.\r\n",
  "laravel-password-resets-tinker": "---\r\ntitle: \"How to manually generate Laravel password resets\"\r\ndate: 2021-01-24\r\n---\r\nInstead of sending password resets via email, you can also generate one whenever you'd like using Laravel Tinker on the command line (even in production) and send it manually.\r\n\r\nFirst, run `php artisan tinker` to open up Laravel Tinker. Then, use this command to generate a password reset token for the `User` with ID `1`.\r\n\r\n```php\r\napp('auth.password.broker')->createToken(App\\User::find(1))\r\n```\r\n\r\nThis returns a token and adds it (hashed) to the `password_resets` table of your database.\r\n\r\nTo use it, use this path:\r\n\r\n```\r\n/password/reset/{token}?email={user_email_address}\r\n```\r\n\r\nTo get this working in production on Laravel Vapor, I ran this command:\r\n\r\n```bash\r\nphp artisan tinker --execute \"error_log(app('auth.password.broker')->createToken(App\\User::find(1)))\"\r\n```\r\n\r\nThe command wasn't actually returning the token in production until I wrapped it with `error_log`.\r\n",
  "laravel-plaintext-emails": "---\r\ntitle: \"Sending plaintext emails in Laravel without a Mailable\"\r\ndate: 2021-02-02\r\n---\r\nSometimes you just want to send a simple email from within a Laravel controller or somewhere else, without having to create a whole \"mailable\" class.\r\n\r\nIn these cases, you can use the `Mail::raw` method:\r\n\r\n```php\r\nuse Illuminate\\Support\\Facades\\Mail;\r\n\r\nMail::raw('Hello there!', function ($message) {\r\n    $message->from('mail@example.com', 'From Name');\r\n    $message->to('recipient@gmail.com');\r\n    $message->subject('You’ve got mail');\r\n});\r\n```\r\n",
  "laravel-return-path": "---\r\ntitle: \"How to set a Return-Path header for Laravel mail\"\r\ndate: 2021-01-27\r\n---\r\nThe `Return-Path` header in an email defines which email address should receive bounces and complaints (such as getting marked as spam). It's useful to set this header so you can monitor how many complaints you're getting, and which emails are bouncing.\r\n\r\nYou can set this header in a Laravel Mailable using the `withSwiftMessage()` method:\r\n\r\n```php\r\npublic function build()\r\n{\r\n    $this->withSwiftMessage(function ($message) {\r\n        $message->getHeaders()\r\n                ->addTextHeader('Return-Path', 'email@example.com');\r\n    });\r\n\r\n    return $this\r\n        ->view('some.view');\r\n        // the rest of the normal mailable methods for from, subject, etc\r\n}\r\n```\r\n\r\nNow, this email will have the `Return-Path` header defined, and receiving email clients will send a notification email to that address if the email bounces or is marked as spam.\r\n",
  "laravel-schedule-job-daily": "---\r\ntitle: \"How to schedule a Laravel job to run daily\"\r\ndate: 2021-01-29\r\n---\r\nLaravel has a built-in scheduler, which allows you to schedule queued jobs to run at certain times.\r\n\r\nFirst, create a job that can be queued, using the `artisan make:job {name}` command, which executes some code in its `handle()` method.\r\n\r\nNow to schedule it, open Laravel's `app/Console/Kernel.php` file. In that file's `schedule()` method, you can have the job run once per day. Here are three options:\r\n\r\n```php\r\n// file: app/Console/Kernel.php\r\n\r\nprotected function schedule(Schedule $schedule)\r\n{\r\n    // Run this job every day at midnight\r\n    $schedule->job(new App\\Jobs\\SomeJob)->daily();\r\n\r\n    // Run this job every day at a certain time (here, 3 p.m.)\r\n    $schedule->job(new App\\Jobs\\SomeJob)->dailyAt('15:00');\r\n\r\n    // You can also set a time zone for the cron job\r\n    $schedule->job(new App\\Jobs\\SomeJob)\r\n        ->timezone('America/New_York')\r\n        ->dailyAt('15:00');\r\n}\r\n```\r\n",
  "laravel-schedule-prevent": "---\r\ntitle: \"How to prevent a Laravel schedule from running at certain times\"\r\ndate: 2021-01-29\r\n---\r\nI had a queued job that I wanted to run every thirty minutes, but only during the daytime.\r\n\r\nTurns out that Laravel has two methods that allow you to control the times of day that a scheduled job is executed: `between` and `unlessBetween`.\r\n\r\n```php\r\n// file: app/Console/Kernel.php\r\n\r\nprotected function schedule(Schedule $schedule)\r\n{\r\n    // Only runs between 7 a.m. and 11 p.m.\r\n    $schedule->job(new App\\Jobs\\SomeJob)\r\n        ->everyThirtyMinutes()\r\n        ->between('7:00', '23:00');\r\n\r\n    // Runs at all times except from 2 a.m. to 8 a.m.\r\n    $schedule->job(new App\\Jobs\\SomeJob)\r\n        ->everyThirtyMinutes()\r\n        ->unlessBetween('2:00', '8:00');\r\n}\r\n\r\n```\r\n\r\nYou can do the same things with either method, so it's up to you to pick whichever one feels better.\r\n",
  "laravel-tinker-dispatch-job": "---\r\ntitle: \"How to dispatch a job locally from Laravel Tinker\"\r\ndate: 2021-01-27\r\n---\r\nWhen developing a Laravel app locally, the `::dispatch()` method might not work from Laravel Tinker, since a real queue driver isn't running.\r\n\r\nInstead, after starting Tinker (`php artisan tinker`), try this command:\r\n\r\n```php\r\n\\Bus::dispatch(new App\\Jobs\\SomeJob($arguments))\r\n```\r\n",
  "livewire-refresh-other-component": "---\r\ntitle: \"How to refresh one Livewire component from another component\"\r\ndate: 2021-01-24\r\n---\r\nSometimes you want to refresh one Livewire component in response to changes in a separate Livewire component.\r\n\r\nFor example, some data you've edited and saved in the first component needs to be shown in the second component.\r\n\r\nFor this, you can use Livewire's events system. First, define the listeners on the Livewire component you want to refresh remotely, so that sending an event called `refreshComponent` will call Livewire's magic `$refresh` method.\r\n\r\n```php\r\nprotected $listeners = ['refreshComponent' => '$refresh'];\r\n```\r\n\r\nNow, in the other component, we just have to send an event called `refreshComponent` to this component.\r\n\r\n```php\r\n$this->emitTo('component-to-refresh', 'refreshComponent')\r\n```\r\n\r\nThis event will be sent to the component called `component-to-refresh`, and `component-to-refresh` will reload its contents.\r\n",
  "livewire-test-class-not-found": "---\r\ntitle: How to solve \"Class 'Tests\\Feature\\Livewire' not found\"\r\ndate: 2021-01-24\r\n---\r\nYou're probably writing a Laravel test for a Livewire component.\r\n\r\n[The docs](https://laravel-livewire.com/docs/testing) don't seem to mention that you need to import a package at the top of your test file first, like this:\r\n\r\n```php\r\nuse Livewire\\Livewire;\r\n```\r\n\r\nNow, you can use `Livewire::test` in your tests!\r\n",
  "livewire-url-changing": "---\r\ntitle: \"How to get current URL in Livewire component\"\r\ndate: 2021-01-24\r\n---\r\nIn Laravel, you can get the current URL by running `url()->current()`. However, Livewire kind of breaks this — after subsequent Livewire requests, the \"current URL\" will be equal to the internal Livewire URL, not the actual page's URL.\r\n\r\nAn easy fix for this is to save the current URL when the component first loads, using the `mount` method. Here's a piece of the Livewire component:\r\n\r\n```php\r\npublic $currentUrl;\r\n\r\npublic function mount()\r\n{\r\n    $this->currentUrl = url()->current();\r\n}\r\n```\r\n\r\nNow, you can use `$currentUrl` in your Livewire component instead of `url()->current()`, and it will work as expected.\r\n",
  "livewire-validation-messages": "---\r\ntitle: \"How to customize validation messages in Livewire\"\r\ndate: 2021-01-24\r\n---\r\nLivewire allows you to write validation in a protected `$rules` property that is used whenever you call `$this->validate()` or `$this->validateOnly('propertyName')`.\r\n\r\nIf you want to show a different error message for one of the validation rules, you can use the protected `$messages` property to do it.\r\n\r\nFor example, say I have this Livewire Blade view, with a simple input and the possibility of showing an error message for that input's value:\r\n\r\n```html\r\n<div>\r\n  <input wire:model=\"text\" />\r\n\r\n  @error('text')\r\n    <p>{{ $message }}</p>\r\n  @enderror\r\n</div>\r\n```\r\n\r\nI could leverage the `$messages` property like this to override the default validation error for the text minimum length rule:\r\n\r\n```php\r\n<?php\r\n\r\nuse Livewire\\Component;\r\n\r\nclass LivewireComponent extends Component\r\n{\r\n    public $text = '';\r\n\r\n    protected $rules = [\r\n        'text' => 'required|min:3'\r\n    ];\r\n\r\n    protected $messages = [\r\n        'text.min' => 'Keep typing...'\r\n    ];\r\n\r\n    public function updated($property)\r\n    {\r\n        // Every time a property changes\r\n        // (only `text` for now), validate it\r\n        $this->validateOnly($property);\r\n    }\r\n\r\n    public function render()\r\n    {\r\n        return view('livewire-component');\r\n    }\r\n}\r\n```\r\n",
  "marked-prism": "---\r\ntitle: \"How to use Marked and Prism.js together\"\r\ndate: 2021-01-24\r\n---\r\nFor this blog, I wanted to parse the blog posts (written in markdown) and also add syntax highlighting to the code blocks so they can have nice readable colors.\r\n\r\nI'm using [Marked](https://github.com/markedjs/marked) to parse markdown into HTML, and [Prism](https://github.com/PrismJS/prism) to parse code blocks within that markdown.\r\n\r\nI wrote this `parseMarkdown()` function to turn raw markdown into HTML with syntax-highlighted code blocks:\r\n\r\n```javascript\r\nconst marked = require('marked')\r\nconst prism = require('prismjs')\r\n\r\nrequire('prismjs/components/prism-markup-templating')\r\nrequire('prismjs/components/prism-css')\r\nrequire('prismjs/components/prism-php')\r\nrequire('prismjs/components/prism-json')\r\nrequire('prismjs/components/prism-javascript')\r\nrequire('prismjs/components/prism-jsx')\r\nrequire('prismjs/components/prism-bash')\r\nrequire('prismjs/components/prism-yaml')\r\nrequire('prismjs/components/prism-toml')\r\n\r\nmarked.setOptions({\r\n  highlight: (code, lang) => {\r\n    if(prism.languages[lang]) {\r\n      return prism.highlight(code, prism.languages[lang], lang)\r\n    } else {\r\n      return code\r\n    }\r\n  }\r\n})\r\n\r\nfunction parseMarkdown(text) {\r\n  return marked.parse(text)\r\n}\r\n```\r\n\r\nFirst, we import the `marked` and `prismjs` packages.\r\n\r\nThen, we import different Prism \"components\" that allow it to parse different languages. The full list of components you can import is [here](https://github.com/PrismJS/prism/tree/master/components).\r\n\r\nThen, we tell Marked that we want to handle code highlighting differently. If the code block has a language indicated, like this:\r\n\r\n<!-- Spaces before the contents of this code block so they're not actually rendered as a code block. -->\r\n````markdown\r\n ```javascript\r\n // we've indicated that this code is javascript\r\n ```\r\n````\r\n\r\n...**and** Prism is able to parse it (tested by seeing whether it's in `prism.languages` - Prism will be able to parse languages that we imported components for), we use `prism.highlight()` to syntax-highlight the code. Otherwise, we just return the code itself.\r\n\r\nNow, if you look at the outputted HTML from the `parseMarkdown()` function, the code blocks are invisibly split up with classes that allow you to use [any Prism CSS theme](https://github.com/PrismJS/prism-themes) to style them.\r\n",
  "marked-quotes": "---\r\ntitle: \"How to get curly quotes with Marked.js\"\r\ndate: 2021-01-24\r\n---\r\nMarked.js is a library for parsing Markdown into HTML.\r\n\r\nI personally think that curly or \"smart\" quotes look better in writing, like this:\r\n\r\n```text\r\n\"straight quotes\"\r\n“curly quotes”\r\nstraight apostrophe: they're\r\ncurly apostrophe: they’re\r\n```\r\n\r\nTo turn straight quotes into curly quotes when parsing with Marked.js, use the `setOptions` function to turn \"smartypants\" rendering on:\r\n\r\n```javascript\r\nmarked.setOptions({ smartypants: true })\r\n\r\nmarked.parse(/* markdown content */)\r\n```\r\n\r\nNow, `marked.parse` will produce HTML with intelligently replaced curly quotes.\r\n",
  "media-hover": "---\r\ntitle: \"How to disable CSS hover styles on phones\"\r\ndate: 2021-01-24\r\n---\r\nCSS styles for hovering (like `a:hover`) can be janky and annoying on touch screen devices that don't support hovering.\r\n\r\nYou can easily fix this by wrapping your hover styles with a CSS media query that detects whether the current device has a cursor that can hover.\r\n\r\n```css\r\n@media (hover: hover) {\r\n  a:hover {\r\n    /* hover styles */\r\n  }\r\n}\r\n```\r\n\r\nNow, the styles inside that `@media` block will only be applied if the device supports hover.\r\n\r\nThe opposite of this is also possible - applying styles only to devices that do not support hovering.\r\n\r\n```css\r\n@media (hover: none) {\r\n  /* styles for touchscreen devices */\r\n}\r\n```\r\n",
  "navigator-sendbeacon": "---\r\ntitle: \"How and why to use navigator.sendBeacon\"\r\ndate: 2021-01-23\r\n---\r\nThe `navigator.sendBeacon()` method makes POST requests without waiting for a response.\r\n\r\nIt's often used for analytics and diagnostics, since it can be called right when a user closes a page and the request will still fire off.\r\n\r\nWhen you call the method like this:\r\n\r\n```jsx\r\nnavigator.sendBeacon(\"/api-url\", JSON.stringify(payload))\r\n```\r\n\r\nThe data is queued and sent when the browser has an opportunity to do so, without getting in the way of other actions. Therefore, it can be more efficient and reliable than the `fetch` API, which may block execution of other code and be a heavier load on the CPU.\r\n\r\nFor example, you might use `navigator.sendBeacon()` to log analytics [right as the page is closed](https://developer.mozilla.org/en-US/docs/Web/API/Window/beforeunload_event). Or, you might use it to efficiently log errors to a server when you detect them in your app, since you don't really care about the response to that request.\r\n\r\nThere's more detailed documentation about this interesting API on [MDN](https://developer.mozilla.org/en-US/docs/Web/API/Navigator/sendBeacon).\r\n",
  "netlify-functions-cors": "---\r\ntitle: \"How to allow CORS on Netlify Functions\"\r\ndate: 2021-01-24\r\n---\r\nCORS is a browser feature that blocks HTTP requests from one domain to another, unless the destination has the proper headers set up.\r\n\r\nIf you run into CORS errors with Netlify functions, you can fix them by returning a header called `access-control-allow-origin` with value `*`. This allows any (signified by `*`) origin (domain name) to make an HTTP request to the function.\r\n\r\nYou can return the header using the Netlify Functions `callback` function:\r\n\r\n```javascript\r\ncallback(null, {\r\n  statusCode: 200,\r\n  body: \"Hello, world!\"\r\n  headers: {\r\n    \"access-control-allow-origin\": \"*\"\r\n  }\r\n})\r\n```\r\n",
  "netlify-toml-gatsby": "---\r\ntitle: \"How to set up netlify.toml for Gatsby\"\r\ndate: 2021-01-23\r\n---\r\nNetlify's configuration file, [netlify.toml](https://docs.netlify.com/configure-builds/file-based-configuration/), allows you to define various settings for how your site will be deployed on Netlify.\r\n\r\nA basic `netlify.toml` file (placed at the root directory of your project) for a Gatsby site looks like this:\r\n\r\n```toml\r\n[build]\r\n    command = \"gatsby build\"\r\n    publish = \"public\"\r\n[dev]\r\n    command = \"gatsby develop\"\r\n```\r\n\r\nThe first `[build]` block tells Netlify that they should run `gatsby build` on their servers whenever you publish a new version of the site, and then publish whatever Gatsby puts in the `public` folder.\r\n\r\nThe second `[dev]` block tells Netlify that it should run `gatsby develop` whenever you run `netlify dev` on the command line to develop locally. Why use `netlify dev` instead of `gatsby develop`, the normal way of starting Gatsby's development server? Running Gatsby's command through [Netlify Dev](https://www.netlify.com/products/dev/) allows you to emulate the final Netlify site more closely. This includes:\r\n\r\n- Pulling in environment variables defined in your Netlify site dashboard\r\n- Performing Netlify redirects you've defined\r\n- Compiling and locally running Netlify Functions\r\n\r\nThere's a lot more you can configure in your `netlify.toml` file, such as environment variables, redirects, headers, and image compression. More information is in [Netlify's documentation](https://docs.netlify.com/configure-builds/file-based-configuration/).\r\n",
  "next-auth-ses": "---\ntitle: How to send NextAuth.js emails with Amazon SES\ndate: 2021-04-23\n---\n\n[NextAuth.js](https://next-auth.js.org) wants you to use an SMTP connection string when using their [\"Email\" authentication provider](https://next-auth.js.org/providers/email).\n\nIt took me a while to figure out how to get an SMTP connection string for Amazon Simple Email Service, but once I did I wrote this quick guide: [How to send email through Amazon SES with SMTP](/ses-smtp).\n\nFollow that guide to set up NextAuth.js like this:\n\n```jsx\nproviders: [\n\tProviders.Email({\n\t\tserver: 'smtp://username:password@email-smtp.us-east-1.amazonaws.com:587',\n\t\tfrom: 'system@example.com' // A domain you've set up in Amazon SES' console\n\t})\n]\n```\n",
  "node-fetch-download-image": "---\ntitle: How to download an image with node-fetch\ndate: 2021-03-28\n---\n\n`node-fetch` is a great package that allows you to use the wonderful `fetch` API in server-side Node.js. It can also be used to request and download images from a URL to the local filesystem!\n\nHere's how you do it, assuming that you have `node-fetch` already installed ( by running `npm install node-fetch`).\n\n```jsx\nconst fs = require('fs') // Built-in filesystem package for Node.js\nconst fetch = require('node-fetch')\n\nconst imageUrl = 'https://via.placeholder.com/350x150'\n\nfetch(imageUrl)\n\t.then(res =>\n\t\tres.body.pipe(fs.createWriteStream('./path/to/image.png'))\n\t)\n```\n\nThis downloads the image at `imageUrl` and \"pipes\" (downloads) it to the given path.\n\n**Note:** Make sure that the folder you're downloading into exists already. If it doesn't, you'll want to create the folders required by doing something like:\n\n```jsx\nconst fs = require('fs')\n\nfs.mkdirSync('./path/to', { recursive: true })\n```\n",
  "node-latex-to-html": "---\r\ntitle: \"How to render LaTeX to HTML with Node.js\"\r\ndate: 2021-01-24\r\n---\r\nTo render LaTeX as HTML, we're going to be using the `KaTeX` [npm package](https://www.npmjs.com/package/katex). First, install it:\r\n\r\n```bash\r\nnpm install katex\r\n```\r\n\r\nNow, to render a string of LaTeX into HTML, we can use that package:\r\n\r\n```javascript\r\nconst katex = require('katex')\r\n\r\nconst latexString = 'e = mc^2'\r\n\r\nconst html = katex.renderToString(latexString)\r\n```\r\n\r\nNow, `html` will be a rendering of the LaTeX in HTML. To make it show properly, you'll need to include KaTeX's special CSS file, which styles the outputted HTML with the correct fonts and positioning. Drop this CSS file into the `<head>` of your HTML file along with the rendered LaTeX:\r\n\r\n```html\r\n<link rel=\"stylesheet\" href=\"https://unpkg.com/katex@0.12.0/dist/katex.min.css\" />\r\n```\r\n\r\nNow, opening the HTML file containing the rendered LaTeX-as-HTML string and that linked CSS file will show the LaTeX beautifully rendered.\r\n",
  "node-minify-css": "---\r\ntitle: \"How to minify CSS with Node.js\"\r\ndate: 2021-01-24\r\n---\r\nWe'll be using PostCSS to easily minify a string of CSS in a Node.js script.\r\n\r\nFirst, install the necessary packages:\r\n\r\n```bash\r\nnpm install postcss cssnano autoprefixer\r\n```\r\n\r\n`postcss` is what we're using the do the minifying, and `cssnano` and `autoprefixer` are *plugins* for PostCSS that tell PostCSS how to manipulate the CSS. `cssnano` comes with a bunch of built-in techniques for making CSS smaller, and `autoprefixer` adds those `-webkit` or `-moz` prefixes where necessary to make your CSS compatible with all browsers.\r\n\r\nNow that you've installed the npm packages, here's how you use them:\r\n\r\n```javascript\r\nconst postcss = require('postcss')\r\nconst cssnano = require('cssnano')\r\nconst autoprefixer = require('autoprefixer')\r\n\r\n// Wrapped in a function so we can use async/await\r\nconst minifyCss = async () => {\r\n  // This CSS might be imported from a file, or anywhere else\r\n  const css = `\r\n    * {\r\n      font-family: system-ui;\r\n    }\r\n  `\r\n\r\n  // We pass in an array of the plugins we want to use: `cssnano` and `autoprefixer`\r\n  const output = await postcss([cssnano, autoprefixer])\r\n    .process(css)\r\n\r\n  // The `css` property of `output` is the minified CSS as a string\r\n  const minifiedCss = output.css\r\n}\r\n\r\nminifyCss()\r\n```\r\n",
  "node-minify-html": "---\r\ntitle: \"How to minify HTML with Node.js\"\r\ndate: 2021-01-24\r\n---\r\nIt's common practice to \"minify\" HTML, removing its extra spaces and unnecessary properties so that it's faster to load.\r\n\r\nYou can use the `html-minifier` npm package to minify HTML.\r\n\r\nFirst, install the package:\r\n\r\n```bash\r\nnpm install html-minifier\r\n```\r\n\r\nNow, you can use the package like this:\r\n\r\n```javascript\r\nconst { minify } = require('html-minifier')\r\n\r\nconst originalHtml = /* html string */;\r\n\r\nconst minifiedHtml = minify(originalHtml, {\r\n  collapseWhitespace: true,\r\n  removeComments: true,\r\n  collapseBooleanAttributes: true,\r\n  useShortDoctype: true,\r\n  removeEmptyAttributes: true,\r\n  removeOptionalTags: true,\r\n  minifyJS: true\r\n})\r\n```\r\n\r\nThere are lots of options for how to minify the HTML, and I've shown the ones that I usually turn on. You can see all the possible options in the [documentation](https://github.com/kangax/html-minifier).\r\n",
  "node-serve-static-files": "---\r\ntitle: \"How to serve static files with Node.js\"\r\ndate: 2021-01-24\r\n---\r\nIf you have a folder of static files and want to serve them using Node.js, you can use a package called `serve-handler`.\r\n\r\nFirst, install the package:\r\n\r\n```bash\r\nnpm install serve-handler\r\n```\r\n\r\nThen, here's an example of how to use it to create a static file server:\r\n\r\n```javascript\r\nconst serveHandler = require('serve-handler')\r\nconst http = require('http') // comes pre-installed with Node.js\r\n\r\nhttp.createServer((req, res) => serveHandler(req, res, {\r\n  public: 'path/to/folder' // folder of files to serve\r\n})).listen(8000)\r\n```\r\n\r\nNow, if you run this Node.js script, you'll have a static file server at `localhost:8000` for the `path/to/folder` directory.\r\n\r\nThere are more options for `serve-handler` (other than `public`) in [the documentation](http://npm.im/serve-handler).\r\n",
  "node-sha1": "---\ntitle: How to sha1 hash with Node.js\ndate: 2021-03-28\n---\n\nYou don't need to install external packages to hash a string using the SHA-1 hashing method.\n\nNode.js comes with a built-in package called `crypto` that you can use. Here's a simple way:\n\n```jsx\nconst crypto = require('crypto')\n\nconst str = 'This is the string I want to hash.'\nconst hash = crypto.createHash('sha1').update(str).digest('hex')\n```\n\nThe resulting `hash` is `str`, hashed using SHA-1 to create a shorter string that is fairly unique to the original string.\n",
  "node-shell": "---\r\ntitle: \"How to execute a shell script with Node.js\"\r\ndate: 2021-01-24\r\n---\r\nYou can execute a shell script with Node.js without even installing any packages.\r\n\r\n```jsx\r\nconst { spawn } = require('child_process')\r\n\r\nspawn('git clone https://github.com/benborgers/potion && cd potion', {\r\n  shell: true\r\n})\r\n```\r\n\r\nThe `shell: true` option allows you to execute any command, like you would on the command line.\r\n\r\nFor more options, like specifying which directory to execute the command in, check out the [official Node.js documentation](https://nodejs.org/api/child_process.html#child_process_child_process_spawn_command_args_options).\r\n",
  "node-spawn-callback": "---\r\ntitle: \"How to get callback when Node.js spawn execution is done\"\r\ndate: 2021-01-24\r\n---\r\nThe built-in `child_process` Node.js package has a `spawn` method that allows you to run a terminal command.\r\n\r\nThere's no built-in way of running a function when the command has finished executing, but `spawn` *does* give us access to a \"done\" event when the command finishes executing.\r\n\r\n```jsx\r\nconst { spawn } = require('child_process')\r\n\r\nconst command = spawn('git clone https://github.com/benborgers/potion', {\r\n  shell: true\r\n})\r\n\r\ncommand.on('close', () => {\r\n  // Code to run when the command finishes\r\n})\r\n```\r\n\r\nYou could even wrap this into a nice, reusable function:\r\n\r\n```jsx\r\nconst { spawn } = require('child_process')\r\n\r\n// Reusable function:\r\nconst executeCommand = textToExecute => new Promise(resolve => {\r\n  const command = spawn(textToExecute, { shell: true })\r\n  command.on('close', () => resolve())\r\n})\r\n\r\n// Usage:\r\nconst main = async () => {\r\n  await executeCommand('git clone https://github.com/benborgers/potion')\r\n\r\n  // Do something here that will only happen after the command has finished.\r\n}\r\nmain()\r\n```\r\n",
  "node-spawn-logging": "---\r\ntitle: \"Logging the output of Node.js shell exec\"\r\ndate: 2021-01-24\r\n---\r\nThe nice thing about the built-in `child_process` package's `spawn` command for executing shell commands with Node.js, is that you can easily get access to the output of that command.\r\n\r\nThis way, you can see what the terminal command is doing:\r\n\r\n```jsx\r\nconst { spawn } = require('child_process')\r\n\r\nconst command = spawn('git clone https://github.com/benborgers/potion', {\r\n  shell: true\r\n})\r\n\r\ncommand.stdout.on('data', data =>   console.log(data.toString())\r\ncommand.stderr.on('data', data => console.error(data.toString())\r\n```\r\n\r\nNow, the output of your `spawn` shell command will be streamed to the console in real time.\r\n",
  "normalize-gatsby": "---\r\ntitle: \"How to add normalize.css to Gatsby\"\r\ndate: 2021-01-23\r\n---\r\n[Normalize.css](https://necolas.github.io/normalize.css/) is a set of CSS rules used to make all browsers render things consistently. Since all browsers come with their own \"base\" styles that can vary slightly, it's useful for making sure that your CSS styles look the same in every browser and smoothes over any inconsistencies between browsers.\r\n\r\nTo add it to your Gatsby site, first install the `normalize.css` npm package using the command line:\r\n\r\n```bash\r\nnpm install normalize.css\r\n```\r\n\r\nThen, import the stylesheet to any Gatsby page you want to use it on:\r\n\r\n```jsx\r\nimport React from \"react\"\r\n\r\nimport \"normalize.css\"\r\n\r\nexport default () => {\r\n  return (\r\n    <div>the page is here</div>\r\n  )\r\n}\r\n```\r\n\r\nYou'll need to do this on every page that you want to use normalize.css on. You can make this less tedious by adding it to the template that multiple pages use (more information can be found [in Gatsby's documentation](https://www.gatsbyjs.org/blog/2019-05-02-how-to-build-a-blog-with-wordpress-and-gatsby-part-3/#creating-a-page-template)), or by adding it to a shared component that all pages import and use.\r\n",
  "notion-blog": "---\r\ntitle: \"How to use Notion as your blog's CMS\"\r\ndate: 2021-01-24\r\n---\r\n\r\n**Heads up!** This post was written before Notion came out with an official API, and uses a reverse-engineering method that isn’t offically supported. Notion now has an official developer API, so you should probably [use that instead](https://developers.notion.com).\r\n\r\n---\r\n\r\nThis blog gets its content from [Notion](https://www.notion.so/product). I write the posts in a table in Notion, and whenever this site is rebuilt on [Vercel](https://vercel.com), the site pulls in all the posts and formats them into HTML.\r\n\r\nTo build this blog, I first reverse-engineered Notion's private API. Notion is working on a public API, but for the time being I decided to build my own API by watching Chrome's dev tools while loading a Notion doc.\r\n\r\nThis turned into an open-source project called [Potion](https://github.com/benborgers/potion), which includes hosted API endpoints that you can use.\r\n\r\n## Setting up Notion\r\n\r\nMy blog posts are written in a full-page table in Notion:\r\n\r\n![](https://user-images.githubusercontent.com/30215449/105618741-caa35700-5db8-11eb-8fe9-0b0710fbd16f.png)\r\n\r\nBecause of Notion's structure for tables, each row in this table is also its own Notion document. This document contains the content of each blog post.\r\n\r\nI also have a few other fields (columns) in the table, which include the URL of the blog post, when it was published, and whether it should be made public. I can use these to transfer each blog post (each row) onto my website.\r\n\r\n## Using the API\r\n\r\nNow for the fun part: pulling in the blog posts from Notion.\r\n\r\nAs I mentioned earlier, building this blog relied heavily on API endpoints from my open-source project [Potion](https://github.com/benborgers/potion), specifically `potion-api.now.sh/table` for getting the list of blog posts and `potion-api.now.sh/html` for getting the HTML for each blog post.\r\n\r\nThere's more documentation in Potion's [README](https://github.com/benborgers/potion/blob/master/README.md), and if you have any questions about how to use Potion feel free to [send me an email](mailto:benborgers@hey.com).\r\n\r\nAlso make sure to set your Notion table to **public sharing** so the API can access it.\r\n\r\nEssentially, when my site is being built, I use [`node-fetch`](https://npm.im/node-fetch) to make a request to `/table` and list out all the blog posts. It filters down to only blog posts where `fields.Published` is `true`, and then builds my site's `/blog` page to list those posts.\r\n\r\nThen, for each published post, it takes the `id` of that row in the table and makes another request to `/html` using that page's ID. This endpoint returns fully-baked HTML of the document's contents. I now just have to insert that HTML into a template for each blog post, along with the title from the earlier `/table` call, and I can generate all the blog post pages (like the one you're looking at right now).\r\n\r\n## Other blog posts\r\n\r\nI've written some other blog posts on using the Potion API for Notion:\r\n\r\n* [API to read a Notion table](/posts/notion-table)\r\n* [How to turn a Notion doc into a website](/posts/notion-to-website)\r\n",
  "notion-table": "---\r\ntitle: \"Reading a Notion table with an API\"\r\ndate: 2021-01-24\r\n---\r\n\r\n**Heads up!** This post was written before Notion came out with an official API, and uses a reverse-engineering method that isn’t offically supported. Notion now has an official developer API, so you should probably [use that instead](https://developers.notion.com).\r\n\r\n---\r\n\r\nI wrote my own reverse-engineered API for Notion, called Potion. The code is open source on [GitHub](https://github.com/benborgers/potion).\r\n\r\nToday, we're going to use that API to read a table in Notion.\r\n\r\n## Getting the table ID\r\n\r\nTo use the API, we need the ID of the table in Notion that we want to read.\r\n\r\nFirst, make the table public using the **Share** button in the top right corner:\r\n\r\n![](https://user-images.githubusercontent.com/30215449/105642546-659f3e00-5e58-11eb-9b4a-bc1e78ee1f49.png)\r\n\r\nThen, click the **Copy page link** button and paste the link somewhere. The long string of characters in the link (but not after the `?`) is the Notion document ID:\r\n\r\n![image](https://user-images.githubusercontent.com/30215449/105642549-6d5ee280-5e58-11eb-92af-a2063be272c6.png)\r\n\r\n\r\n*The ID in this example is `2364751436224832ba85e279417ea798`.*\r\n\r\nYou'll need to give this ID to the API in order to tell it which table to read from.\r\n\r\n## Using the Potion API\r\n\r\nNow, we'll use [Potion](https://potion-api.now.sh) to read the table.\r\n\r\nThe endpoint we want to send a GET request to is:\r\n\r\n```\r\nhttps://potion-api.now.sh/table?id=NOTION_DOCUMENT_ID\r\n```\r\n\r\nYou can click [here](https://potion-api.now.sh/table?id=2364751436224832ba85e279417ea798) and see what the response would look like with the example ID we copied earlier, which is the ID for [this table](https://notion.so/2364751436224832ba85e279417ea798).\r\n\r\nHere's an example for javascript using `fetch`, which is built in to the browser:\r\n\r\n```jsx\r\nfetch(\"https://potion-api.now.sh/table?id=2364751436224832ba85e279417ea798\")\r\n  .then(res => res.json())\r\n  .then(json => {\r\n    console.log(json)\r\n  })\r\n```\r\n\r\nFrom here, you can use the data however you'd like. Feel free to use it to populate a website, read data for running a daily script, etc. This opens up a ton of new possibilities!\r\n",
  "notion-to-website": "---\r\ntitle: \"How to turn a Notion doc into a website\"\r\ndate: 2021-01-24\r\n---\r\n\r\n**Heads up!** This post was written before Notion came out with an official API, and uses a reverse-engineering method that isn’t offically supported. Notion now has an official developer API, so you should probably [use that instead](https://developers.notion.com).\r\n\r\n---\r\n\r\nI wrote my own reverse-engineered API for Notion, called Potion. The code is open source on [GitHub](https://github.com/benborgers/potion).\r\n\r\nToday, we're going to use that API to turn a Notion document into a website.\r\n\r\nThere's two ways of doing it: using a **static website** (no server), or using a **Node.js server**. We'll also discuss the pros and cons of each.\r\n\r\n## Getting the ID of your Notion doc\r\n\r\nFor both of these methods, you'll need the ID of your Notion doc.\r\n\r\nFirst, make the Notion doc public using the **Share** button in the top right corner:\r\n\r\n![](https://user-images.githubusercontent.com/30215449/105642488-03463d80-5e58-11eb-96c8-88e3e24ba1a5.png)\r\n\r\n\r\nThen, click the **Copy page link** button and paste it somewhere. The long random string of characters in that link is the document ID:\r\n\r\n![](https://user-images.githubusercontent.com/30215449/105642493-0b9e7880-5e58-11eb-85fe-2191ddb4ef18.png)\r\n\r\nWe'll use this ID in our code later.\r\n\r\n## Method 1: Static website\r\n\r\nThe benefits of this approach are that you can host the website very cheaply (for example, on [Netlify](https://netlify.com)) since it's just static files. However, the webpage is empty before the javascript executes, and crawlers (like Google) need to run the javascript in order to \"see\" the contents.\r\n\r\nLet's set up the skeleton of the web page:\r\n\r\n```jsx\r\n<!DOCTYPE html>\r\n<html lang=\"en\">\r\n  <head>\r\n    <title>Notion Doc</title>\r\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\r\n    <link rel=\"stylesheet\" href=\"/style.css\" />\r\n    <script src=\"/script.js\" defer></script>\r\n  </head>\r\n  <body>\r\n    <main></main>\r\n  </body>\r\n</html>\r\n```\r\n\r\nThis empty HTML page links a javascript file (at `/script.js`) and a CSS file (`/style.css`).\r\n\r\nI also added an empty `<main>` element in the body, which is where we'll load the Notion doc into.\r\n\r\nThen, I wrote some javascript in `script.js` that makes a request to the Potion API and fills in the `<main>` element with the result. It uses the Notion document ID you copied earlier.\r\n\r\n```jsx\r\nconst notionDocId = \"0cb628857f3c4c77bf7f9a879a6ec21d\"\r\n\r\nfetch(\"https://potion-api.now.sh/html?id=\" + notionDocId)\r\n  .then(res => res.text())\r\n  .then(text => {\r\n    document.querySelector(\"main\").innerHTML = text\r\n  })\r\n```\r\n\r\nThat's it! Now you have a website powered by your Notion doc. Here's the full code if you'd like to check it out: [Live demo](https://notion-to-website-static.glitch.me) and [source code](https://glitch.com/edit/#!/notion-to-website-static).\r\n\r\n## Method 2: Node.js server\r\n\r\nThe benefits of this approach are that the HTML sent by the server fully includes the Notion document's content, so it's easy for web crawlers (like Google) to read and understand. It doesn't require any client-side javascript to run. However, you need to run a full Node.js server to host it, so this solution can't be hosted on a static file host.\r\n\r\nI started by installing `express`, a framework for Node.js servers, and `node-fetch`, a package that replicates the `fetch` API in Node.js.\r\n\r\n```jsx\r\nconst express = require(\"express\")\r\nconst app = express()\r\n\r\nconst fetch = require(\"node-fetch\")\r\n\r\napp.listen(process.env.PORT)\r\n```\r\n\r\nThen, I added this Express route. It uses the Notion doc ID you copied earlier, makes a request to the Potion API, and then inserts the result of the API request in an HTML document on the server.\r\n\r\n```jsx\r\napp.get(\"/\", (req, res) => {\r\n  const notionDocId = \"0cb628857f3c4c77bf7f9a879a6ec21d\"\r\n\r\n  fetch(\"https://potion-api.now.sh/html?id=\" + notionDocId)\r\n    .then(res => res.text())\r\n    .then(text => {\r\n      res.send(`\r\n        <!DOCTYPE html>\r\n        <html>\r\n          <head>\r\n            <title>Notion Doc</title>\r\n            <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\r\n            <style>\r\n              body {\r\n                font-family: system-ui, sans-serif;\r\n              }\r\n\r\n              img {\r\n                max-width: 100%;\r\n                max-height: 70vh;\r\n              }\r\n\r\n              /* add your own CSS to make it look how you want */\r\n            </style>\r\n          </head>\r\n          <body>\r\n            <main>${text}</main>\r\n          </body>\r\n        </html>\r\n      `)\r\n    })\r\n})\r\n```\r\n\r\nThis website looks the exact same, but is generated on the server-side instead of in the browser. Here's the full code for the Node.js solution: [Live demo](https://notion-to-website-node.glitch.me) and [source code](https://glitch.com/edit/#!/notion-to-website-node).\r\n",
  "php-datetime-add-days": "---\r\ntitle: \"Easiest way to add days to a PHP DateTime\"\r\ndate: 2021-01-24\r\n---\r\nIf you have a PHP `DateTime` instance and want to add a certain number of days to it, you can use the `modify` method. Here's an example:\r\n\r\n```php\r\n$date = new DateTime('NOW')->modify('+1 day');\r\n```\r\n\r\nNow, `$date` is a `DateTime` 1 day in the future from now.\r\n\r\nYou can substitute any number of days into the `modify` method, or make it a variable like this:\r\n\r\n```php\r\n$date = new DateTime('NOW')->modify(\"+{$daysToAdd} days\");\r\n```\r\n",
  "psql": "---\ntitle: How to install \"psql\" command for PostgreSQL on macOS\ndate: 2021-04-23\n---\n\nYou can really install the `psql` command for Postgres if you have [Homebrew](https://brew.sh) installed.\n\nJust run these two commands:\n\n```bash\nbrew install postgresql\nbrew services start postgresql\n```\n\nNow, the `psql` command will work locally on your Mac.\n",
  "pwa-detect-installed": "---\r\ntitle: \"How to detect if your PWA is installed\"\r\ndate: 2021-01-24\r\n---\r\nYou might want to show a different UI in your progressive web app depending on whether the app's \"downloaded\" (added to the user's home screen) vs. when it's not.\r\n\r\nYou have to detect this in two different ways: one for iOS, and one for Android. Here's how to do it in javascript:\r\n\r\n```javascript\r\nfunction isInstalled() {\r\n  // For iOS\r\n  if(window.navigator.standalone) return true\r\n\r\n  // For Android\r\n  if(window.matchMedia('(display-mode: standalone)').matches) return true\r\n\r\n  // If neither is true, it's not installed\r\n  return false\r\n}\r\n```\r\n\r\nYou can now call this function `isInstalled()` in your app's javascript to see whether the user has added the app to their home screen yet.\r\n",
  "react-helmet-async": "---\r\ntitle: \"How to fix \\\"componentWillMount has been renamed\\\"\"\r\ndate: 2021-01-23\r\n---\r\nI was using the [react-helmet](https://npm.im/react-helmet) package, and noticed an error in my console saying:\r\n\r\n> Warning: componentWillMount has been renamed, and is not recommended for use. See https://fb.me/react-async-component-lifecycle-hooks for details.\r\n\r\nTurns out, in React 17 (the next version of React), the `componentWillMount` method will no longer work. `react-helmet` relies on this method, and therefore there's a warning when you try to use `componentWillMount` in React 16.9+.\r\n\r\n## Solution\r\n\r\nThere's a virtually identical package called [react-helmet-async](https://npm.im/react-helmet-async), which doesn't have this error and will continue working through React 17.\r\n\r\nInstalling and replacing `react-helmet` with `react-helmet-async` everywhere in my code got rid of the warning for me.\r\n\r\nTo install, run:\r\n\r\n```bash\r\nnpm install react-helmet-async\r\n```\r\n\r\nAnd then use the new package just as you would use `react-helmet`:\r\n\r\n```javascript\r\nimport { Helmet } from \"react-helmet-async\"\r\n\r\n// ... etc\r\n```\r\n\r\n## Solving it in Gatsby\r\n\r\nIf your site is built with [Gatsby](https://gatsbyjs.org/), you're probably currently using [gatsby-plugin-react-helmet](https://www.gatsbyjs.org/packages/gatsby-plugin-react-helmet/). You'll need to replace this plugin with [@rhysforyou/gatsby-plugin-react-helmet-async](https://www.gatsbyjs.org/packages/@rhysforyou/gatsby-plugin-react-helmet-async).\r\n",
  "react-native-right-align": "---\r\ntitle: \"How to right-align an element in React Native\"\r\ndate: 2021-01-24\r\n---\r\nRight aligning a component can be hard in React Native, especially when you don't want to just use `text-align: right`.\r\n\r\nLuckily, you can use flexbox to right-align an element by setting two properties on a wrapping `View`.\r\n\r\n```jsx\r\nexport default () => {\r\n  return (\r\n    <View\r\n      style={{\r\n        flexDirection: \"row\",\r\n        justifyContent: \"flex-end\"\r\n      }}\r\n    >\r\n      <Button\r\n        title=\"Click me\"\r\n        onPress={() => console.log(\"clicked\")}\r\n      />\r\n    </View>\r\n  )\r\n}\r\n```\r\n",
  "react-native-width": "---\r\ntitle: \"How to set Text to max-width: max-content in React Native\"\r\ndate: 2021-01-24\r\n---\r\nIn regular CSS you can give an element the property `max-width: max-content`, which makes the element (at most) as wide as the text inside of it.\r\n\r\nThere's no direct equivalent in React Native, but instead you can use flexbox to emulate this behavior to make a `Text` element only as wide as the text inside.\r\n\r\n```jsx\r\nexport default () => {\r\n  return (\r\n    <View\r\n      style={{\r\n        alignSelf: \"flex-start\"\r\n      }}\r\n    >\r\n      <Text>Hello, world!</Text>\r\n    </View>\r\n  )\r\n}\r\n```\r\n",
  "react-static-head": "---\ntitle: How to add things to the HTML head with React Static\ndate: 2021-04-07\n---\n\nReact Static comes with a built-in `Head` component, which allows you to add content to the HTML `<head>` element. It's powered by [React Helmet](https://github.com/nfl/react-helmet).\n\n```jsx\nimport { Head } from 'react-static'\n\nexport default () => {\n\treturn (\n\t\t<div>\n\t\t\t<Head>\n\t\t\t\t<title>Here is the page title</title>\n\t\t\t</Head>\n\n\t\t\t<div>\n\t\t\t\tthe page content\n\t\t\t</div>\n\t\t</div>\n\t)\n}\n```\n",
  "react-static-scroll": "---\ntitle: How to reset scroll on route change with React Static\ndate: 2021-04-08\n---\n\nReact Static seems to have an issue where, if you click on a link a bit down on a page, it keeps you scrolled down on the next page. That's not standard behavior, but luckily it's fairly easy to fix.\n\nFirst, I exported an extra function called `useLocation` from my Router component, so we can use it in a moment. By default, this component lives at `src/components/Router`.\n\n```jsx\n// src/components/Router\n\nexport { Link, Router, useLocation } from '@reach/router'\n```\n\nI created a new component in `src/App.js` called `<ScrollToTop />` that scrolls to the top of the page whenever the page changes.\n\n```jsx\n// src/App.js\nimport React, { useLayoutEffect } from 'react'\nimport { Root, Routes } from 'react-static'\n\nimport { Router, useLocation } from 'components/Router'\n\nfunction App() {\n    return (\n        <Root>\n            <React.Suspense fallback={<em>Loading...</em>}>\n\t\t\t\t{/* Here it is! */}\n                <ScrollToTop />\n\n                <Router>\n                    <Routes path=\"*\" />\n                </Router>\n            </React.Suspense>\n        </Root>\n    )\n}\n\nfunction ScrollToTop() {\n    const { pathname } = useLocation()\n\n    useLayoutEffect(() => {\n        window.scrollTo(0, 0)\n    }, [pathname])\n\n    return null\n}\n\nexport default App\n```\n\nI just declared the component at the bottom of the file, and then included it in the root `App` component.\n\nThis uses the `useLocation` function that we exported from the router, and uses React's `useLayoutEffect` (which is like `useEffect` but runs after all DOM mutations for a less jarring scroll reset) to scroll to the top of the page every time the URL path changes.\n",
  "react-static-sitemap": "---\ntitle: How to get absolute URLs in a React Static sitemap\ndate: 2021-04-07\n---\n\nWhen I first generated used `react-static-plugin-sitemap`, it outputted a sitemap (at the URL `/sitemap.xml`) with URLs that are relative, meaning that they only start with `/`.\n\nSitemaps aren't supposed to have relative URLs, they're supposed to have full URLs (which start with `http://` or `https://` and include the domain).\n\nThis problem arises because React Static doesn't know which domain your site is going to be published at. You can fix this by adding a property to the object exported by `static.config.js`:\n\n```jsx\n// static.config.js\n\nexport default {\n\tsiteRoot: 'https://example.com'\n}\n```\n\nNow, the URLs in `sitemap.xml` will have the full domain in them.\n",
  "react-static-tailwind": "---\ntitle: How to use Tailwind CSS with React Static\ndate: 2021-04-09\n---\n\nFirst, install all the necessary dependencies:\n\n```bash\nnpm install tailwindcss autoprefixer postcss postcss-cli\n```\n\nTailwind is by itself a plugin for PostCSS, and PostCSS is a tool for transforming CSS. To create a PostCSS configuration file, run :\n\n```bash\nnpx tailwindcss init -p\n```\n\nThis will create both a `postcss.config.js` and `tailwind.config.js` file. The PostCSS config file will be set up to use the `autoprefixer` plugin too (which we installed at the beginning), which will add browser-specific prefixes to your CSS so it works in all browsers.\n\nIn your `tailwind.config.js` file, set the `purge` option to point to your React components. This will allow Tailwind to remove the CSS classes you didn't use to make the final CSS file smaller in production. If your React components are in the `src/` directory, for example:\n\n```jsx\n// excerpt from tailwind.config.js\npurge: ['./src/**/*.js']\n```\n\nNext, fill out your CSS file. Some React Static templates have the CSS file at `src/app.css`, so we'll replace the contents of that file with this:\n\n```css\n@tailwind base;\n@tailwind components;\n@tailwind utilities;\n```\n\nWhen this file goes through PostCSS, those three `@tailwind` directives will be replaced with the full Tailwind CSS framework.\n\nWe're nearing the end here! We need to add commands for building this CSS file, both in development and production. We'll use the PostCSS CLI (which we installed earlier) for that, and modify the following two commands in your `package.json`:\n\n```json\n// excerpt from package.json\n\"start\": \"NODE_ENV=development postcss src/app.css > dist.css && react-static start\",\n\"build\": \"NODE_ENV=production postcss src/app.css > dist.css && react-static build\"\n```\n\nIt's important to define `NODE_ENV`, because that determines whether Tailwind will \"purge\" all your unused classes.\n\nThose commands output the built version of `src/app.css` to a file called `dist.css`. You'll see it in your project's folder after running either of those commands.\n\nWe don't really want that file to be uploaded to Git, so we'll add it to our `.gitignore` file so it doesn't get committed. This is optional, and only if you're using Git for version control.\n\n```bash\n# excerpt from .gitignore file\ndist.css\n```\n\nLastly! We want to actually use that outputted `dist.css` file. In your `src/App.js` component, there's a line that imports the `./app.css` file. However, that's the un-built CSS file — the fully processed and built one lives at `dist.css`. So switch that import line in `src/App.js` to this:\n\n```jsx\nimport '../dist.css'\n```\n\nAnd that's it! Now you have Tailwind CSS working with a React Static website, both in development and production.\n",
  "route53-list-dns": "---\r\ntitle: \"How to list DNS records using the Route53 Node.js API\"\r\ndate: 2021-01-24\r\n---\r\nRecently, I had a project where I wanted to programmatically get all the DNS records for my domain. The DNS was being handled on AWS Route53.\r\n\r\nFirst, I created an IAM User for my code to use (it's AWS' version of an API key):\r\n\r\n1. Open the the [IAM Users](https://console.aws.amazon.com/iam/home#/users) page in the AWS dashboard.\r\n2. Click \"Add User\", give it a name, and select \"programmatic access\".\r\n3. Select \"Attach existing policies directly\" and search for `AmazonRoute53ReadOnlyAccess`. This means that this key will only be able to _read_ Route53 resources, not modify them or access anything else.\r\n4. Go through the rest of the setup steps and note the access key ID and secret access keys generated at the end.\r\n\r\nIn your project, create a JSON file (I called mine `aws.json`) with your keys in it:\r\n\r\n```json\r\n{\r\n    \"accessKeyId\": \"AKIA5POZ6AJXFCGJPE4H\",\r\n    \"secretAccessKey\": \"n1YrVagQ8/Cz3nwLMoiK4OlSudzbKFCbVzMRZhjI\",\r\n    \"region\": \"us-east-1\"\r\n}\r\n```\r\n\r\nNext, open up your [Hosted zones](https://console.aws.amazon.com/route53/v2/hostedzones#) on Route53 and open the domain whose DNS records you want to read. Copy down the ID at the end of the URL bar — it'll probably start with a `Z`.\r\n\r\nNow, you're ready to use the AWS API:\r\n\r\n```javascript\r\nconst AWS = require('aws-sdk')\r\n\r\nAWS.config.loadFromPath('./aws.json') // your JSON file with access keys\r\nconst route53 = new AWS.Route53()\r\n\r\nroute53.listResourceRecordSets({\r\n    HostedZoneId: 'Z...', // hosted zone ID from earlier\r\n    MaxItems: '300'\r\n}, (err, data) => {\r\n    console.log(data)\r\n})\r\n```\r\n\r\nAnd that's it! You can look at the logged `data` variable to see the DNS records for this domain.\r\n",
  "route53-pricing": "---\ntitle: \"How much do domains cost from AWS Route 53?\"\ndate: 2021-01-24\n---\nAmazon Web Services doesn't make it super clear how much registering, renewing, or transferring a domain costs on Route53.\n\nAfter some digging, I found [their price list PDF](https://d32ze2gidvkk54.cloudfront.net/Amazon_Route_53_Domain_Registration_Pricing_20140731.pdf), so I wanted to share.\n",
  "ses-smtp": "---\ntitle: How to send email through Amazon SES with SMTP\ndate: 2021-04-24\n---\n\nFirst, you'll need to create your SMTP credentials for AWS Simple Email Service (SES):\n\n- On the old SES console, there's an **SMTP Settings** link on the left side.\n- On the new SES console, the link is under **Account dashboard** on the left sidebar.\n\nGo through the steps to create new SMTP credentials, and copy them down somewhere.\n\nThe fully formed SMTP connection string looks like this:\n\n```plain\nsmtp://username:password@email-smtp.us-east-1.amazonaws.com:587\n```\n\nThere are three variables that you should replace in this string:\n\n- `username` and `password`, which are the SMTP credentials you copied down earlier.\n- `us-east-1`, which you should replace with the region that you're sending emails from ([this page has a list of the endpoints](https://docs.aws.amazon.com/general/latest/gr/ses.html)).\n",
  "speed-up-gatsby-on-netlify": "---\ntitle: \"How to speed up Gatsby builds on Netlify\"\ndate: 2021-01-24\n---\nI recently discovered that you can greatly improve the speed of Gatsby builds on Netlify, especially if you have a lot of images being optimized with `gatsby-image`, through the Netlify plugin **Gatsby Cache**.\n\nOpen your [Netlify dashboard](https://app.netlify.com) and click on the **Plugins** tab. Search for \"Gatsby Cache\" and click **Install**, then find your Gatsby site and install the plugin to that site.\n\nThis plugin will take effect on future builds, and it'll persist the Gatsby build cache between changes. This means that Gatsby will be able to intelligently save time, such as not re-optimizing images that haven't changed.\n",
  "subreddit-json": "---\ntitle: \"How to get subreddit posts as JSON\"\ndate: 2021-01-24\n---\nYou can get data from any subreddit or Reddit user in JSON format, using Reddit's free and dead-simple API.\n\nJust add `.json` to the end of a Reddit URL:\n\n- [reddit.com/r/worldnews.json](https://reddit.com/r/worldnews.json)\n- [reddit.com/user/spez.json](https://www.reddit.com/user/spez.json)\n",
  "swr-refresh": "---\r\ntitle: \"How to refresh data with SWR\"\r\ndate: 2021-01-24\r\n---\r\nLet's say you have a piece of data you're fetching with Vercel's [SWR package](https://github.com/vercel/swr):\r\n\r\n```jsx\r\nconst { data } = useSWR(\"/posts\")\r\n```\r\n\r\nIf you want to refresh this data, you can do this by making use of other values returned by `useSWR`.\r\n\r\n```jsx\r\nconst { data, mutate, isValidating } = useSWR(\"/posts\")\r\n// isValidating will be explained later\r\n```\r\n\r\nYou can change the cached `data` for `/posts` by calling `mutate(newData)`.\r\n\r\nHowever, if you just run `mutate()`, it will refresh the data for `/posts` in the background. `mutate` knows to request the `/posts` endpoint again, since that's where the `mutate` function came from.\r\n\r\n## Bonus: isValidating\r\n\r\nYou can use `isValidating` to show to the user whether the data has been updated yet.\r\n\r\nThis value is `true` while SWR is refetching the data, and `false` once the data has been successfully returned.\r\n\r\nYou can use `isValidating` to conditionally show a message that says something like *Updating...* while new data is being fetched.\r\n",
  "tailwind-colors": "---\r\ntitle: \"How to customize the Tailwind CSS 2.0 color palette\"\r\ndate: 2021-01-24\r\n---\r\nTailwind 2.0 comes with less colors by default, but has a wider range of color palettes that you can activate if you need them.\r\n\r\nWe'll do this by \"extending\" the Tailwind configuration, instead of overwriting the default colors.\r\n\r\nCreate or edit a file at the root of your project called `tailwind.config.js`. In it, you need to have this:\r\n\r\n```javascript\r\nconst color = require('tailwindcss/colors')\r\n\r\nmodule.exports = {\r\n  theme: {\r\n    extend: {\r\n      colors: {\r\n        // Colors you want to add go here\r\n        rose: colors.rose,\r\n        cyan: colors.cyan\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nIn this example, we've added rose and cyan to the Tailwind color palette. This means you can now use them as text colors, background colors, gradients, or anywhere else in Tailwind that uses colors.\r\n\r\nNow, next time you build your CSS file, those colors will be included in all the color-related utility classes.\r\n\r\nYou can see the full list of colors that you can use in [Tailwind's documentation](https://tailwindcss.com/docs/customizing-colors#color-palette-reference).\r\n",
  "tailwind-font": "---\ntitle: How to customize font in Tailwind CSS\ndate: 2021-03-30\n---\n\nTailwind CSS comes with default `.font-sans`, `.font-serif`, and `.font-mono` classes. But sometimes, you want to add your own font family, or customize one of the existing classes.\n\nYou can do this with your `tailwind.config.js` file using the **extend** functionality.\n\n```jsx\n// tailwind.config.js\n\nconst defaultTheme = require('tailwindcss/defaultTheme')\n\nmodule.exports = {\n\tvariants: {\n\t\textend: {\n\t\t\tfontFamily: {\n\t\t\t\tsans: ['\"DM Sans\"', ...defaultTheme.fontFamily.sans],\n\t\t\t\tcursive: ['cursive']\n\t\t\t}\n\t\t}\n\t}\n}\n```\n\nThe `sans` line overwrites Tailwind's `.font-sans` class with your own font at the front, but then falls back to the Tailwind stack if your custom font doesn't load. The `cursive` line creates a new class called `.font-cursive` that has that font stack.\n\nNow, next time you rebuild your Tailwind CSS file, those changes will be made to the font classes.\n\nNotice that font names that contain a space must have additional quotes around them.\n",
  "tailwind-gradient-text": "---\r\ntitle: \"How to make gradient text with Tailwind CSS\"\r\ndate: 2021-01-24\r\n---\r\nTailwind now includes all the necessary utilities for easily making gradient text!\r\n\r\nYou'll just need to combine these classes:\r\n\r\n- `bg-gradient-to-{direction}` sets the background to a gradient, you can use different classes from [the Tailwind docs](https://tailwindcss.com/docs/background-image) to make the gradient go in different directions\r\n- `from-{color}` sets the color that the gradient is starting at, this accepts any usual Tailwind color (e.g. `from-pink-400`)\r\n- `to-{color}` sets the color that the gradient ends at, same as above\r\n- `text-transparent` makes the text transparent so you can see the gradient behind it\r\n- `bg-clip-text` makes the background only appear within the text\r\n\r\nPutting it all together, here's an example of a big gradient text headline:\r\n\r\n```html\r\n<h1 class=\"text-5xl font-extrabold text-transparent bg-clip-text bg-gradient-to-br from-pink-400 to-red-600\">\r\n  Hello, world!\r\n</h1>\r\n```\r\n\r\nYou can see and edit this example live on [Tailwind Play](https://play.tailwindcss.com/T8EUKtz8B0).\r\n",
  "tailwind-grid": "---\ntitle: How to create custom CSS Grids with Tailwind JIT mode\ndate: 2021-07-07\n---\n\nIf you have [just-in-time compiler](https://tailwindcss.com/docs/just-in-time-mode) activated for TailwindCSS, you can now define custom CSS grid layouts just using utility classes that are generated on the fly.\n\nTo use it, just list out the measurements you would normally write with a comma in between.\n\nInstead of this CSS:\n\n```css\ndisplay: grid;\ngrid-template-rows: 2.5rem max-content 1fr;\n```\n\nYou can use these classes:\n\n```html\n<div class=\"grid grid-rows-[2.5rem,max-content,1fr]\"></div>\n```\n\nThis has some benefits, such as being able to apply different grid layouts at different breakpoints:\n\n```html\n<div class=\"grid grid-rows-[1rem,1fr] sm:grid-rows-[2.5rem,1fr]\"></div>\n```\n",
  "tailwind-postcss-error": "---\r\ntitle: \"How to fix \\\"PostCSS plugin tailwindcss requires PostCSS 8\\\"\"\r\ndate: 2021-01-24\r\n---\r\nI just upgraded to Tailwind 2.0 from Tailwind 1.0, and got the error \"PostCSS plugin tailwindcss requires PostCSS 8\" when I tried to rebuild my CSS bundle.\r\n\r\nI was using Laravel Mix to compile the assets, but this solution should work for any situation where you get this error.\r\n\r\nSince PostCSS 8 is new, many tools still use PostCSS 7. Tailwind maintains a `compat` channel that works with PostCSS 7, which is completely identical to the flagship PostCSS 8 version.\r\n\r\nTo install it, first uninstall the default modules you might've installed:\r\n\r\n```bash\r\nnpm uninstall tailwindcss postcss autoprefixer\r\n```\r\n\r\nThen, install specific versions of these modules:\r\n\r\n```bash\r\nnpm install tailwindcss@npm:@tailwindcss/postcss7-compat postcss@^7 autoprefixer@^9\r\n```\r\n\r\nYou'll notice that you're installing the `compat` version of Tailwind.\r\n\r\nAnd just like that, your Tailwind CSS build should work again!\r\n",
  "tailwind-typography-customize": "---\ntitle: How to customize Tailwind Typography plugin\ndate: 2021-04-09\n---\n\nYou can customize the styles applied by the `@tailwindcss/typography` plugin in your `tailwind.config.js` file:\n\n```jsx\n// tailwind.config.js\n\nmodule.exports = {\n\ttheme: {\n\t\textend: {\n\t\t\ttypography: theme => ({\n\t\t\t\tDEFAULT: {\n\t\t\t\t\tcss: {\n\t\t\t\t\t\tcolor: theme('colors.blue.500'),\n\t\t\t\t\t\ttextDecoration: 'none'\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t},\n\tplugins: [\n\t\trequire('@tailwindcss/typography')\n\t]\n}\n```\n\nThe `theme` helper function lets you access values from your Tailwind config. I find it helpful to reference the [default Tailwind config](https://github.com/tailwindlabs/tailwindcss/blob/master/stubs/defaultConfig.stub.js) when using this helper.\n\nIt's also helpful to reference the [default Tailwind typography config](https://github.com/tailwindlabs/tailwindcss-typography/blob/master/src/styles.js) to figure out what you want to override.\n",
  "terminal-mkdir": "---\r\ntitle: \"Terminal create directory if it doesn't exist\"\r\ndate: 2021-01-24\r\n---\r\nIf you want to create a directory using bash (in the terminal), but you don't know whether it'll already exist so you only want to create it if the directory doesn't exist yet:\r\n\r\n```bash\r\nmkdir -p directory\r\nmkdir -p my/directory/here\r\n```\r\n\r\nYou can use this with a top-level directory (the first example), or with a deeply nested directory (the second example).\r\n\r\nThe `-p` flag creates all directories necessary along the way (for example `my`, `directory`, and `here`) **if** they don't exist yet.\r\n",
  "textarea-tab": "---\r\ntitle: How to add \"tab to indent\" to a textarea\r\ndate: 2021-01-24\r\n---\r\nI was building a textarea meant for writing markdown, and I wanted users to be able to hit the `tab` key and insert an indent (when nesting bullet points, for example).\r\n\r\nThis turned out to be quite straightforward, using just a bit of javascript.\r\n\r\nI first added the text box to my HTML:\r\n\r\n```html\r\n<textarea></textarea>\r\n```\r\n\r\nAnd then added the behavior using javascript:\r\n\r\n```javascript\r\nconst textarea = document.querySelector('textarea')\r\n\r\ntextarea.addEventListener('keydown', (e) => {\r\n  if (e.keyCode === 9) {\r\n    e.preventDefault()\r\n\r\n    textarea.setRangeText(\r\n      '  ',\r\n      textarea.selectionStart,\r\n      textarea.selectionStart,\r\n      'end'\r\n    )\r\n  }\r\n})\r\n```\r\n\r\nThis javascript adds a listener for whenever a key is pressed inside the textarea. If the `keyCode` is `9` (which is the key code for the `tab` key), we `preventDefault()` — this means preventing the browser's default behavior, which is usually leaving the textarea to go to the next element.\r\n\r\nNow, we use `setRangeText()`, which allows us to manipulate text in the textarea. We put two spaces, simulating a tab, at the point where the cursor currently is. `setRangeText()` usually overwrites text, but by telling it to start and end at the same spot (second and third arguments), it inserts text instead. Lastly, `end` moves the cursor to the end of the inserted text, which is the behavior we want.\r\n\r\nThat's it! [Here's a CodeSandbox](https://codesandbox.io/s/textarea-tab-ivvhq?file=/index.html) demonstrating the solution.\r\n",
  "tiptap-selection": "---\ntitle: How to get current text selection with tiptap\ndate: 2021-07-08\n---\n\nIf you’re using the [tiptap](https://tiptap.dev) editor, it can be difficult to figure out how to get the currently selected (highlighted) text.\n\nTo do this, you have to drop down to ProseMirror, the library that tiptap is built on top of. With a given tiptap instance (`editor`), you can access the internal `EditorView` from ProseMirror at `editor.view`.\n\nTherefore we can get the current selection with:\n\n```js\neditor.view.state.selection\n```\n\nThis returns an instance of the `Selection` class, which is [documented here in ProseMirror's documentation](https://prosemirror.net/docs/ref/#state.Selection). You can use all the methods listed in that documentation, and run them on `editor.view.state.selection`.\n\nFor example, to check whether any text is actually currently highlighted in the tiptap editor, you would do this:\n\n```js\nconst currentSelectionIsEmpty = editor.view.state.selection.empty\n```\n",
  "trix-disable-files": "---\r\ntitle: \"Disabling file uploads with the Trix editor\"\r\ndate: 2021-01-24\r\n---\r\nBasecamp's [Trix](https://trix-editor.org) text editor lets people upload their own files into the text they're writing, but maybe you don't want to deal with file uploads at the moment.\r\n\r\nTo disable file uploads, first remove the \"file\" button (it looks like a paperclip) using CSS:\r\n\r\n```css\r\ntrix-toolbar [data-trix-button-group=\"file-tools\"] {\r\n  display: none;\r\n}\r\n```\r\n\r\nThis removes the button, but it doesn't stop people from dragging files in. For that, add this javascript that ignores file uploads whenever one is attempted:\r\n\r\n```jsx\r\ndocument.addEventListener(\"trix-file-accept\", event => {\r\n  event.preventDefault()\r\n})\r\n```\r\n",
  "vapor-database": "---\r\ntitle: \"How to attach a database to a Laravel Vapor deployment\"\r\ndate: 2021-01-24\r\n---\r\nYou can attach an Amazon RDS database to a Laravel Vapor deployment, which automatically configures your Laravel app to use that database.\r\n\r\nFirst, [create a database on Vapor](https://docs.vapor.build/1.0/resources/databases.html#creating-databases) using the UI or the CLI.\r\n\r\nThen, add it to your `vapor.yml` file for your app:\r\n\r\n```yaml\r\nid: 10583\r\nname: my-app\r\nenvironments:\r\n    production:\r\n        # Add the database like this:\r\n        database: my-database-name\r\n        # More configuration would go here\r\n```\r\n\r\nNow, next time you redeploy to Laravel Vapor, your app will have the necessary environment variables to connect to the database you specified.\r\n",
  "vapor-maintenance": "---\r\ntitle: \"How to customize the Laravel Vapor maintenance view\"\r\ndate: 2021-01-24\r\n---\r\nIf you want to take a Laravel Vapor app down temporarily, you run this command from within the app:\r\n\r\n```bash\r\nvapor down production # this is for environment called \"production\"\r\n```\r\n\r\nTo bring it back up, you run:\r\n\r\n```bash\r\nvapor up production\r\n```\r\n\r\nWhile it's down, Vapor will show a general maintenance mode page. A lot of tutorials tell you to customize this by writing a view at `resources/views/errors/503.blade.php`. However, this **isn't the case for Laravel Vapor**.\r\n\r\nOn Vapor, you customize this by putting a file called `503.html` at the root of your application (not in the `resources/views/` folder — at the root, outside any folders).\r\n\r\nInside this self-contained file, write the plain HTML that you want to be shown when your app is in maintenance mode.\r\n",
  "vapor-migrations": "---\r\ntitle: \"How to run migrations automatically on Laravel Vapor\"\r\ndate: 2021-01-24\r\n---\r\nYou can't run database migrations manually when a Laravel app is in production. Instead, define a deploy hook in `vapor.yml`:\r\n\r\n```yaml\r\n# Not a full vapor.yml configuration\r\n\r\nenvironments:\r\n  production:\r\n    deploy:\r\n      - 'php artisan migrate --force'\r\n```\r\n\r\nThe `--force` flag confirms that you're okay with running destructive migrations, such as deleting a column.\r\n\r\nVapor will run this command before the deployment is finalized, making any necessary changes to the production database.\r\n",
  "vapor-trix-attachments": "---\r\ntitle: \"Handling Trix file attachments on Laravel Vapor\"\r\ndate: 2021-01-24\r\n---\r\nAfter a couple hours of work, I've finally gotten file attachments with Basecamp's Trix editor to work on Laravel Vapor.\r\n\r\nTo start, let's assume you have a basic Trix form set up, which mirrors its contents into an `input`. Getting to this point is fairly straightforward with the [Trix docs](https://github.com/basecamp/trix).\r\n\r\n```html\r\n<input type=\"hidden\" name=\"body\" id=\"body\" />\r\n<trix-editor input=\"body\"></trix-editor>\r\n```\r\n\r\nWhen the form with this input is submitted, I can grab the HTML in my Laravel controller like this:\r\n\r\n```php\r\n$body = request('body');\r\n```\r\n\r\n## The plan\r\n\r\nWith Laravel Vapor, you upload your files to Amazon S3 from the client-side. They go into a `tmp/` folder, where files are cleared when they're more than 24 hours old.\r\n\r\nOnce you're sure a file in the `tmp/` folder should be kept (i.e. the user really submitted the form), you copy it out of the `tmp/` folder to keep it around permanently.\r\n\r\nWe want to upload attachments to the `tmp/` folder in S3 as soon as they're dragged into the Trix editor, and keep track of which attachments are still in the Trix document. If the attachment is removed from Trix before the form is submitted, we don't want to copy that attachment out of `tmp/`.\r\n\r\n## Setup\r\n\r\nThere's some setup required to make sure this works when you develop locally.\r\n\r\n## Creating a bucket\r\n\r\nFirst, [attach a storage bucket](https://docs.vapor.build/1.0/resources/storage.html) in your `vapor.yml` file:\r\n\r\n```yaml\r\n# Abbreviated for clarity\r\n\r\nenvironments:\r\n  production:\r\n    storage: my-bucket\r\n```\r\n\r\nThen, deploy your project to Vapor. This will automatically create a bucket in S3 called `my-bucket`, which you can inspect in the S3 Console of your AWS account.\r\n\r\n## Allowing users to upload to the bucket\r\n\r\nPer the [Laravel Vapor docs](https://docs.vapor.build/1.0/resources/storage.html#authorization), we need to create a policy that allows users to upload files to the bucket. Run this command to create the policy:\r\n\r\n```bash\r\nphp artisan make:policy UserPolicy --model=User\r\n```\r\n\r\nAnd then add a function to the newly created policy file that allows any user to upload files:\r\n\r\n```php\r\npublic function uploadFiles(User $user)\r\n{\r\n  return true;\r\n}\r\n```\r\n\r\n## Local access to the bucket\r\n\r\nIn order to access this bucket from your local environment too, modify or add these values in your `.env` file:\r\n\r\n```\r\nFILESYSTEM_DRIVER=s3\r\n\r\nAWS_ACCESS_KEY_ID=\r\nAWS_SECRET_ACCESS_KEY=\r\nAWS_DEFAULT_REGION=us-east-1\r\nAWS_BUCKET=my-bucket\r\n```\r\n\r\nYou'll need to generate a set of IAM credentials for AWS, so you can access the S3 bucket locally. When developing locally, Vapor uploads files to the bucket specified under `AWS_BUCKET` using the IAM access keys provided. To keep things simple, we'll upload to the same bucket that we'll use in production (the one we created in `vapor.yml`).\r\n\r\n## Making the bucket's contents public\r\n\r\nYou'll also need to open your S3 bucket up to public read access. This is so that Trix can display temporary files that are dragged in, and so that you can show the persisted files later (after they're copied out of `tmp/`).\r\n\r\nLog in to the [S3 Console](https://s3.console.aws.amazon.com/), and select the bucket you just created. Go to the **Permissions** tab, then **Bucket Policy**. Paste in the following policy, replacing \"`my-bucket`\" with your bucket's name:\r\n\r\n```\r\n{\r\n  \"Version\": \"2012-10-17\",\r\n  \"Statement\": [\r\n    {\r\n      \"Sid\": \"PublicReadGetObject\",\r\n      \"Effect\": \"Allow\",\r\n      \"Principal\": \"*\",\r\n      \"Action\": \"s3:GetObject\",\r\n      \"Resource\": \"arn:aws:s3:::my-bucket/*\"\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\nKeep in mind that this makes every file in the bucket public (that is, if someone is given the randomly generated filename).\r\n\r\n## Installing dependencies\r\n\r\nYou'll need to install Vapor's javascript package to upload files from the frontend:\r\n\r\n```bash\r\nnpm install laravel-vapor\r\n```\r\n\r\nAnd you'll need to install a PHP dependency for working with S3:\r\n\r\n```bash\r\ncomposer require league/flysystem-aws-s3-v3\r\n```\r\n\r\n## Making the frontend work\r\n\r\nTo start, let's add an extra input to our `<form>`. This input will keep track of which attachments are currently in the Trix editor, which we'll need to copy into permanent storage once the form is submitted.\r\n\r\n```bash\r\n<input type=\"hidden\" name=\"trix_files\" value=\"[]\" />\r\n```\r\n\r\n*Notice that the value is an empty array if no attachments are ever added.*\r\n\r\nHere's all the client-side javascript that makes uploading files work. I'll explain it below.\r\n\r\n```javascript\r\nwindow.Vapor = require('laravel-vapor')\r\n\r\ndocument.addEventListener('trix-attachment-add', event => {\r\n  if(event.attachment.file) {\r\n    const attachment = event.attachment\r\n\r\n    Vapor.store(attachment.file, {\r\n      progress: amount => attachment.setUploadProgress(amount * 100)\r\n\t})\r\n      .then(response => {\r\n        attachment.setAttributes({\r\n          key: response.key,\r\n          url: response.url.split('?')[0]\r\n        })\r\n\r\n        updateTrixFiles(event)\r\n    })\r\n  }\r\n})\r\n\r\nconst updateTrixFiles = event => {\r\n  const allAttachments = event.attachment.attachmentManager.managedAttachments\r\n  const keys = Object.keys(allAttachments).map(id => allAttachments[id].attachment.attributes.values.key)\r\n\r\n  const input = document.querySelector('input[name=\"trix_files\"]')\r\n  input.value = JSON.stringify(keys)\r\n}\r\n\r\ndocument.addEventListener('trix-attachment-remove', updateTrixFiles)\r\n```\r\n\r\nYou'll see that this utilizes the `laravel-vapor` npm package we installed earlier.\r\n\r\nWhen there's a new attachment (event `trix-attachment-add`), we store the file (`attachment.file`) and report its upload progress to the Trix UI.\r\n\r\nAfter it's uploaded, we give Trix its \"key\" (where the attachment is stored in the bucket, like `tmp/random-filename`) and the URL that Trix should use to show it in the editor (the URL provided by Vapor has a bunch of query strings that interfere, so we remove those first).\r\n\r\nThen, once the attachment's been uploaded, we check which files are currently in the Trix document. The `updateTrixFiles` function uses Trix's attachment manager to find the `key` of each attachment (which we provided earlier using `attachment.setAttributes`). It then populates the `trix_files` input, so the backend will know which files need to be persisted.\r\n\r\nWhen an attachment is removed from the Trix editor (event `trix-attachment-remove`), we make sure to update the `trix_files` hidden input once again, to make sure we have the most up-to-date list of attachments that are still in the editor.\r\n\r\n## Making the backend work\r\n\r\nWhen this form is submitted, we have two pieces of data we need to worry about:\r\n\r\n* `body` contains the Trix HTML\r\n* `trix_files` includes the list of temporary files in S3 we now need to copy into permanent S3 storage (since remember, `tmp/` gets erased after 24 hours)\r\n\r\nTo persist the files in S3, we use the `Storage` facade in our controller:\r\n\r\n```php\r\nuse Illuminate\\Support\\Facades\\Storage;\r\n\r\n$files = json_decode(request('trix_files'));\r\n\r\nforeach($files as $path) {\r\n\tStorage::copy($path, str_replace('tmp/', '', $path);\r\n}\r\n```\r\n\r\nNow, those files are copied out of `tmp/` into the root folder in S3, where they won't be deleted after 24 hours.\r\n\r\nLastly, we need to deal with the fact that the Trix HTML (submitted to the controller as `body`) still uses the S3 URLs with `tmp/` in them (we provided the temporary URL to `attachment.setAttributes` on the frontend because the permanent URL didn't exist yet).\r\n\r\nTo fix this, we can find and replace using a regex:\r\n\r\n```php\r\n$body = preg_replace('/tmp\\//', '', request('body'));\r\n```\r\n\r\nNow, the images in the HTML output point to the non-temporary copy of the attachment in S3.\r\n\r\n```\r\nBefore replacement: https://my-bucket.s3.amazonaws.com/tmp/random-filename\r\n After replacement: https://my-bucket.s3.amazonaws.com/random-filename\r\n```\r\n",
  "vercel-cors": "---\r\ntitle: \"How to allows CORS on Vercel\"\r\ndate: 2021-01-26\r\n---\r\nCORS is a browser feature that blocks HTTP requests from one domain to another, unless the destination has the proper headers set up.\r\n\r\nI recently ran into these problems when making an HTTP request from my website to [Potion](https://github.com/benborgers/potion), an API I build for [Notion](https://notion.so) notes.\r\n\r\nI fixed it by adding headers to my [Vercel](https://vercel.com) deployment that allowed HTTP requests from any domain.\r\n\r\nHere's my `vercel.json` file:\r\n\r\n```json\r\n{\r\n  \"headers\": [\r\n    {\r\n      \"source\": \"/(.*)\",\r\n      \"headers\": [\r\n        {\r\n          \"key\": \"access-control-allow-origin\",\r\n          \"value\": \"*\"\r\n        }\r\n      ]\r\n    }\r\n  ]\r\n}\r\n```\r\n",
  "vscode-spellcheck": "---\ntitle: \"How to get spellcheck in VS Code\"\ndate: 2021-01-24\n---\nI wanted to have spellcheck in VS Code for when I was writing blog posts in markdown or README files.\n\nTurns out, there's an easy extension for that! Just install [Spell Right](https://marketplace.visualstudio.com/items?itemName=ban.spellright), and it'll check the spelling of your plaintext and markdown documents, and even in code comments.\n",
  "weather-gov": "---\nlayout: ../../layouts/post\ntitle: How to use the weather.gov API\ndate: 2021-06-19\n---\n\nThe National Weather Service has a really solid free weather API for the United States that you can use.\n\nForecasts are divided into grids, and you can query the forecast for a given grid cell. You probably don't know that grid cell's identifier though, so we can make another API request first using coordinates.\n\nIf you don't have the coordinates of the location you'd like weather from, one easy way is to find it on [Google Maps](https://google.com/maps), right click, and then click the coordinates to copy them.\n\nFirst, make a GET request to this URL with the coordinates:\n\n```plaintext\nhttps://api.weather.gov/points/{latitude},{longitude}\n```\n\nFor example:\n```plaintext\nhttps://api.weather.gov/points/40.7484,-73.9856\n```\n\nThe JSON response contains a URL at `properties.forecast` which is the URL that will give you the forecast for that location. In this case, that URL is:\n\n```plaintext\nhttps://api.weather.gov/gridpoints/OKX/33,36/forecast\n```\n\nYou'll notice that this URL includes the National Weather Service office code for this location (`OKX`), grid x-coordinate (`33`), and grid y-coordinate (`36`).\n\nIf you make a request to this forecast URL, the `properties.periods` array will contain the weather forecast!\n",
  "webkit-tap-highlight-color": "---\r\ntitle: \"How to remove gray box when tapping a link on iOS with CSS\"\r\ndate: 2021-01-24\r\n---\r\nWhen you tap a link in iOS Safari, a gray highlight box appears around it. This can be jarring and might not fit with the rest of your website, so you can use CSS to remove it.\r\n\r\nHere's how you remove it:\r\n\r\n```css\r\n* {\r\n  -webkit-tap-highlight-color: transparent;\r\n}\r\n```\r\n\r\nHowever, this might cause the user not to realize that they tapped something. I like to fix this by using javascript to fading out tapped items to 50% opacity. That way, the user realizes that the button's been tapped and that we're loading the next page.\r\n",
  "zeit-regions": "---\r\ntitle: \"How to deploy to multiple regions with Vercel\"\r\ndate: 2021-01-26\r\n---\r\nWhen deploying projects with [Vercel](https://vercel.com) (formerly ZEIT), you want to deploy the serverless functions as close to your users as possible.\r\n\r\nThis results in slower loading times, since the server is physically closer to your users.\r\n\r\nIn your `vercel.json` file, you can configure the region where the project is deployed:\r\n\r\n```json\r\n{\r\n  \"regions\": [\"iad1\"]\r\n}\r\n```\r\n\r\nThe region identifier (`iad1` in the example above) comes from [the list of regions](https://zeit.co/docs/v2/network/regions-and-providers#routing). Any region marked as an **origin** will work.\r\n\r\nTo see where these locations are, use [this list](https://vercel.com/docs/edge-network/regions#routing).\r\n\r\n_According to support as of March 8, 2020, you can only use one region in the array._\r\n"
}