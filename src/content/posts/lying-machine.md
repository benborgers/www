---
title: We put the lying machine into the correct answer website
date: 2025-10-14
cover_image: /posts/lying-machine/cover_image.png
draft: false
starred: false
unlisted: false
---
The other day, I saw a colleague ask a specific question about the inner workings of the app that my team works on.

They had also put their question into Google. And Google had diligently answered — or more specifically, the AI Overview had spat out a confident answer.

The answer, of course, was not correct. How could it be! Google has no idea about the inner workings of my team's software. It actually knew about the *existence* of our app, but the information about how it worked was a complete guess.

What struck me, though, is that we've trained people for decades that search engines are the gateway to answering questions on the internet. And the line between "that's something you can ask Google" and "that's something Google definitely doesn't know" is hard to teach to everyone. That line is more of a feeling.

This wasn't a problem until recently. Overly niche queries turned up no results, which wasn't helpful, but it was honest.

But now, Google will respond to *every single query* using the power of AI. LLMs, wonderful as they are, are also notorious for hallucinating and confidently lying — especially when they have no better answer to give. **We've put the Notorious Lying Machine into The Website That Tells You Correct Answers.**

Google will now attempt to answer *every single question you ask* confidently and earnestly. That means that, unlike pre-Google AI Overview, it's important for people to understand the limitations of Google — because Google won't demonstrate those limitations itself.

Unfortunately, teaching everyone what Google can and can't answer seems kind of impossible. On the other hand, I am a scared baby bear, and Google can help me find my mama.

![](/posts/lying-machine/2025-10-14%20at%2022.01.19@2x.png)
