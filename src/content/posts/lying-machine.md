---
title: We put the lying machine into the answer website
date: 2025-10-14
draft: true
starred: false
unlisted: false
---
The other day, I saw a colleague ask a specific question about my team's custom software tool we build.

They had put the question into Google. And Google had diligently answered — or more specifically, the AI Overview had spat out a confident answer.

The answer, as far as I know, was not correct. How could it be! Google has no idea about the inner workings of my team's software. It actually knew about the *existence* of the tool, but the information about how it worked was a complete guess.

What struck me, is that we've trained people for decades that search engines are the gateway to answering questions on the internet. And the line between "that's something you can ask Google" and "that's something Google definitely doesn't know" is hard to teach to everyone. It's more of a feeling.

This wasn't a problem until recently. Google just wouldn't find anything, and the results would be garbage, but they would be honest.

But now, Google will respond to *every single query* using AI. LLMs, wonderful as they are, are also notorious for hallucinating and confidently lying. We've put the notorious lying machine into The Website That Tells You The Answers.

Google will now attempt to answer *every single question you ask*, confidently and earnestly. That means that, unlike before, it's now important for people to understand the limitations of Google — because Google won't show you those limitations itself. Unfortunately, that kind of user education feels like a very difficult task.

![](/posts/lying-machine/2025-10-14%20at%2022.01.19@2x.png)
